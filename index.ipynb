{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization and Optimization Lab\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this lab, we'll gain experience detecting and dealing with a ANN model that is overfitting using various regularization and hyperparameter tuning techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "In this lab, we'll work with a large dataset of customer complaints to a bank, with the goal of predicting what product the customer is complaining about based on the text of their complaint.  There are 7 different possible products that we can predict, making this a multi-class classification task. \n",
    "\n",
    "\n",
    "#### Preprocessing our Data Set\n",
    "We'll start by preprocessing our dataset by tokenizing the complaints and limiting the number of words we consider to reduce dimensionality. \n",
    "\n",
    "#### Building our Tuning our Model\n",
    "Once we have preprocessed our data set, we'll build a model and explore the various ways that we can reduce overfitting using the following strategies:\n",
    "- Early stopping to minimize the discrepancy between train and test accuracy.\n",
    "- L1 and L2 regularization.\n",
    "- Dropout regularization.\n",
    "- Using more data.\n",
    "\n",
    "\n",
    "**_Let's Get Started!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing the Bank Complaints Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import the libraries and take a sample\n",
    "\n",
    "Run the cell below to import everything we'll need for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the cell below, import our data into a DataFrame.  The data is currently stored in `Bank_complaints.csv`.\n",
    "Then, `.describe()` the dataset to get a feel for what we're working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('Bank_complaints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed things up during the development process (and also to give us the ability to see how adding more data affects our model performance), we're going to work with a sample of our dataset rather than the whole thing.  The entire dataset consists of 60,000 rows--we're going to build a model using only 10,000 items randomly sampled from this.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Get a random sample of `10000` items from our dataset (HINT: use the `df` object's `.sample()` method to make this easy)\n",
    "* Reset the indexes on these samples to `range(10000)`, so that the indices for our rows are sequential and make sense.\n",
    "* Store our labels, which are found in `\"Product\"`, in a different variable.\n",
    "* Store the data, found in `\"Consumer complaint narrative`, in the variable `complaints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000)\n",
    "df.index = range(10000)\n",
    "product = df['Product']\n",
    "complaints = df['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenizing the Complaints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll only keep 2,000 most common words and use one-hot encoding to quickly vectorize our dataset from text into a format that a neural network can work with. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Create a `Tokenizer()` object, and set the `num_words` parameter to `2000`.\n",
    "* Call the tokenizer object's `fit_on_texts()` method and pass in our `complaints` variable we created above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create some text sequences by calling the `tokenizer` object's `.texts_to_sequences()` method and feeding in our `complaints` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll convert our text data from text to a vectorized matrix.  \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Call the `tokenizer` object's `.texts_to_matrix` method, passing in our `complaints` variable, as well as setting the `mode` parameter equal to `'binary'`.\n",
    "* Store the tokenizer's `.word_index` in the appropriate variable.\n",
    "* Check the `np.shape()` of our `one_hot_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results= tokenizer.texts_to_matrix(complaints, mode = 'binary')\n",
    "word_index = tokenizer.word_index\n",
    "np.shape(one_hot_results) # Expected Results (10000, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 One-hot Encoding of the Products Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tokenized and encoded our text data, we still need to one-hot encode our label data.  \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "\n",
    "* Create a `LabelEncoder` object, which can found inside the `preprocessing` module.\n",
    "* `fit` the label encoder we just created to `product`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what classes our label encoder found.  Run the cell below to examine a list of classes that `product` contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bank account or service',\n",
       " 'Checking or savings account',\n",
       " 'Consumer Loan',\n",
       " 'Credit card',\n",
       " 'Credit reporting',\n",
       " 'Mortgage',\n",
       " 'Student loan']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " list(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll need to transform `product` into a numeric vector.  \n",
    "\n",
    "In the cell below, use the label encoder's `.transform` method on `product` to create an integer encoded version of our labels. \n",
    "\n",
    "Then, access `product_cat` to see an example of how the labels are now encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 3, 1, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_cat = le.transform(product)\n",
    "product_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to go from integer encoding to one-hot encoding.  Use the `to_categorical` method from keras to do this easily in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_onehot = to_categorical(product_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the shape of our one-hot encoded labels to make sure everything worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(product_onehot) # Expected Output: (10000, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train - test split\n",
    "\n",
    "Now, we'll split our data into training and testing sets.  \n",
    "\n",
    "\n",
    "We'll accomplish this by generating a random list of 1500 different indices between 1 and 10000.  Then, we'll slice these rows and store them as our test set, and delete them from the training set (it's very important to remember to remove them from the training set!)\n",
    "\n",
    "Run the cell below to create a set of random indices for our test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = random.sample(range(1,10000), 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now:\n",
    "\n",
    "* Slice the `test_index` rows from `one_hot_results` and store them in `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = one_hot_results[test_index]\n",
    "\n",
    "# This line returns a version of our one_hot_results that has every item with an index in test_index removed\n",
    "train = np.delete(one_hot_results, test_index, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll need to repeat the splitting process on our labels, making sure that we use the same indices we used to split our data. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Slice `test_index` from `product_onehot`\n",
    "* Use `np.delete` to remove `test_index` items from `product_onehot` (the syntax is exactly the same above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = product_onehot[test_index]\n",
    "label_train = np.delete(product_onehot, test_index, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the shape everything we just did to make sure that the dimensions match up.  \n",
    "\n",
    "In the cell below, use `np.shape` to check the shape of:\n",
    "\n",
    "* `label_test`\n",
    "* `label_train`\n",
    "* `test`\n",
    "* `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 7)\n",
      "(8500, 7)\n",
      "(1500, 2000)\n",
      "(8500, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(label_test)) # Expected Output: (1500, 7)\n",
    "print(np.shape(label_train)) # Expected Output: (8500, 7)\n",
    "print(np.shape(test)) # Expected Output: (1500, 2000)\n",
    "print(np.shape(train)) # Expected Output: (8500, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we mentioned that in deep learning, we generally keep aside a validation set, which is used during hyperparameter tuning. Then when we have made the final model decision, the test set is used to define the final model perforance. \n",
    "\n",
    "In this example, let's take the first 1000 cases out of the training set to become the validation set. You should do this for both `train` and `label_train`.\n",
    "\n",
    "Run the cell below to create our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "val = train[:1000]\n",
    "train_final = train[1000:]\n",
    "label_val = label_train[:1000]\n",
    "label_train_final = label_train[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating, compiling and running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because we are dealing with a multiclass problem (classifying the complaints into 7 classes), we use a use a softmax classifyer in order to output 7 class probabilities per case.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Import `Sequential` from the appropriate module in keras.\n",
    "* Import `Dense` from the appropriate module in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a model with the following specifications in the cell below:\n",
    "\n",
    "* An input layer of shape `(2000,)`\n",
    "* Hidden layer 1: Dense, 50 neurons, relu activation \n",
    "* Hidden layer 2: Dense, 25 neurons, relu activation\n",
    "* Output layer: Dense, 7 neurons, softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_shape = (2000, ))) \n",
    "model.add(Dense(25, activation = 'relu'))\n",
    "model.add(Dense(7, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, `compile` the model with the following settings:\n",
    "\n",
    "* Optimizer is `\"SGD\"`\n",
    "* Loss is `'categorical_crossentropy'`\n",
    "* metrics is `['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Train the model for 120 epochs in mini-batches of 256 samples. Also pass in `(val, label_val)` to the `validation_data` parameter, so that we see how our model does on the test set after every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.9576 - accuracy: 0.1521 - val_loss: 1.9426 - val_accuracy: 0.1720\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.9352 - accuracy: 0.1776 - val_loss: 1.9260 - val_accuracy: 0.2130\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.9182 - accuracy: 0.2065 - val_loss: 1.9116 - val_accuracy: 0.2170\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.9017 - accuracy: 0.2337 - val_loss: 1.8957 - val_accuracy: 0.2390\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8830 - accuracy: 0.2577 - val_loss: 1.8746 - val_accuracy: 0.2690\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8592 - accuracy: 0.2885 - val_loss: 1.8484 - val_accuracy: 0.3000\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8302 - accuracy: 0.3163 - val_loss: 1.8169 - val_accuracy: 0.3260\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7959 - accuracy: 0.3461 - val_loss: 1.7818 - val_accuracy: 0.3520\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7570 - accuracy: 0.3768 - val_loss: 1.7412 - val_accuracy: 0.3700\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7141 - accuracy: 0.4031 - val_loss: 1.6981 - val_accuracy: 0.4090\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.6681 - accuracy: 0.4337 - val_loss: 1.6519 - val_accuracy: 0.4190\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.6196 - accuracy: 0.4512 - val_loss: 1.6056 - val_accuracy: 0.4420\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5697 - accuracy: 0.4716 - val_loss: 1.5556 - val_accuracy: 0.4610\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5190 - accuracy: 0.4877 - val_loss: 1.5045 - val_accuracy: 0.4780\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4685 - accuracy: 0.5027 - val_loss: 1.4545 - val_accuracy: 0.4990\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4182 - accuracy: 0.5181 - val_loss: 1.4042 - val_accuracy: 0.5210\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3690 - accuracy: 0.5339 - val_loss: 1.3573 - val_accuracy: 0.5370\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3217 - accuracy: 0.5445 - val_loss: 1.3122 - val_accuracy: 0.5440\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2764 - accuracy: 0.5671 - val_loss: 1.2693 - val_accuracy: 0.5560\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2331 - accuracy: 0.5760 - val_loss: 1.2291 - val_accuracy: 0.5610\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1924 - accuracy: 0.5895 - val_loss: 1.1895 - val_accuracy: 0.5760\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1541 - accuracy: 0.6051 - val_loss: 1.1554 - val_accuracy: 0.5870\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1182 - accuracy: 0.6148 - val_loss: 1.1219 - val_accuracy: 0.6030\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0842 - accuracy: 0.6292 - val_loss: 1.0897 - val_accuracy: 0.6220\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0526 - accuracy: 0.6425 - val_loss: 1.0605 - val_accuracy: 0.6300\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0230 - accuracy: 0.6529 - val_loss: 1.0378 - val_accuracy: 0.6390\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9953 - accuracy: 0.6636 - val_loss: 1.0115 - val_accuracy: 0.6420\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9689 - accuracy: 0.6759 - val_loss: 0.9865 - val_accuracy: 0.6590\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9440 - accuracy: 0.6847 - val_loss: 0.9658 - val_accuracy: 0.6670\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9205 - accuracy: 0.6944 - val_loss: 0.9464 - val_accuracy: 0.6670\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.7001 - val_loss: 0.9319 - val_accuracy: 0.6680\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8772 - accuracy: 0.7087 - val_loss: 0.9110 - val_accuracy: 0.6710\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8575 - accuracy: 0.7136 - val_loss: 0.8916 - val_accuracy: 0.6820\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.7195 - val_loss: 0.8792 - val_accuracy: 0.6780\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8209 - accuracy: 0.7248 - val_loss: 0.8631 - val_accuracy: 0.6900\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8039 - accuracy: 0.7323 - val_loss: 0.8506 - val_accuracy: 0.6930\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7878 - accuracy: 0.7349 - val_loss: 0.8362 - val_accuracy: 0.6970\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7729 - accuracy: 0.7405 - val_loss: 0.8249 - val_accuracy: 0.6980\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.7425 - val_loss: 0.8149 - val_accuracy: 0.6980\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.7473 - val_loss: 0.8035 - val_accuracy: 0.7060\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.7503 - val_loss: 0.7934 - val_accuracy: 0.7150\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7209 - accuracy: 0.7521 - val_loss: 0.7830 - val_accuracy: 0.7190\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.7567 - val_loss: 0.7771 - val_accuracy: 0.7120\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.7581 - val_loss: 0.7692 - val_accuracy: 0.7240\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.7641 - val_loss: 0.7611 - val_accuracy: 0.7220\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.7636 - val_loss: 0.7533 - val_accuracy: 0.7300\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.7679 - val_loss: 0.7493 - val_accuracy: 0.7260\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.7699 - val_loss: 0.7470 - val_accuracy: 0.7240\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.7737 - val_loss: 0.7381 - val_accuracy: 0.7280\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.7779 - val_loss: 0.7323 - val_accuracy: 0.7300\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7793 - val_loss: 0.7303 - val_accuracy: 0.7250\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7819 - val_loss: 0.7200 - val_accuracy: 0.7350\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7851 - val_loss: 0.7173 - val_accuracy: 0.7390\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7879 - val_loss: 0.7136 - val_accuracy: 0.7350\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7895 - val_loss: 0.7094 - val_accuracy: 0.7410\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7921 - val_loss: 0.7078 - val_accuracy: 0.7340\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7945 - val_loss: 0.7032 - val_accuracy: 0.7370\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7957 - val_loss: 0.7005 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7981 - val_loss: 0.7003 - val_accuracy: 0.7370\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7983 - val_loss: 0.6927 - val_accuracy: 0.7490\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.8044 - val_loss: 0.6897 - val_accuracy: 0.7400\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.8047 - val_loss: 0.6841 - val_accuracy: 0.7470\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.8069 - val_loss: 0.6823 - val_accuracy: 0.7500\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.8075 - val_loss: 0.6832 - val_accuracy: 0.7420\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.8111 - val_loss: 0.6828 - val_accuracy: 0.7420\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8119 - val_loss: 0.6785 - val_accuracy: 0.7450\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.8115 - val_loss: 0.6747 - val_accuracy: 0.7510\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.8159 - val_loss: 0.6759 - val_accuracy: 0.7550\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.8164 - val_loss: 0.6728 - val_accuracy: 0.7520\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.8203 - val_loss: 0.6749 - val_accuracy: 0.7510\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8211 - val_loss: 0.6671 - val_accuracy: 0.7550\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8243 - val_loss: 0.6641 - val_accuracy: 0.7620\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.8259 - val_loss: 0.6658 - val_accuracy: 0.7570\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.8247 - val_loss: 0.6628 - val_accuracy: 0.7610\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.8273 - val_loss: 0.6627 - val_accuracy: 0.7580\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8303 - val_loss: 0.6645 - val_accuracy: 0.7510\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8324 - val_loss: 0.6597 - val_accuracy: 0.7580\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8327 - val_loss: 0.6586 - val_accuracy: 0.7600\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.8380 - val_loss: 0.6597 - val_accuracy: 0.7540\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8368 - val_loss: 0.6564 - val_accuracy: 0.7550\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8399 - val_loss: 0.6590 - val_accuracy: 0.7550\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.8421 - val_loss: 0.6529 - val_accuracy: 0.7550\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8427 - val_loss: 0.6567 - val_accuracy: 0.7580\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8439 - val_loss: 0.6519 - val_accuracy: 0.7620\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8455 - val_loss: 0.6508 - val_accuracy: 0.7560\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8485 - val_loss: 0.6506 - val_accuracy: 0.7570\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8497 - val_loss: 0.6553 - val_accuracy: 0.7570\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8496 - val_loss: 0.6542 - val_accuracy: 0.7580\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8509 - val_loss: 0.6511 - val_accuracy: 0.7570\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8523 - val_loss: 0.6525 - val_accuracy: 0.7560\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8532 - val_loss: 0.6482 - val_accuracy: 0.7580\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8552 - val_loss: 0.6496 - val_accuracy: 0.7580\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8577 - val_loss: 0.6461 - val_accuracy: 0.7580\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8589 - val_loss: 0.6440 - val_accuracy: 0.7580\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8591 - val_loss: 0.6471 - val_accuracy: 0.7550\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8620 - val_loss: 0.6469 - val_accuracy: 0.7660\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8633 - val_loss: 0.6471 - val_accuracy: 0.7600\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8633 - val_loss: 0.6505 - val_accuracy: 0.7570\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8631 - val_loss: 0.6451 - val_accuracy: 0.7690\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8660 - val_loss: 0.6504 - val_accuracy: 0.7600\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8660 - val_loss: 0.6512 - val_accuracy: 0.7550\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8689 - val_loss: 0.6454 - val_accuracy: 0.7610\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8689 - val_loss: 0.6462 - val_accuracy: 0.7580\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8704 - val_loss: 0.6452 - val_accuracy: 0.7650\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8728 - val_loss: 0.6479 - val_accuracy: 0.7620\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8741 - val_loss: 0.6444 - val_accuracy: 0.7570\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8744 - val_loss: 0.6487 - val_accuracy: 0.7580\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8751 - val_loss: 0.6506 - val_accuracy: 0.7560\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8741 - val_loss: 0.6430 - val_accuracy: 0.7640\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8769 - val_loss: 0.6446 - val_accuracy: 0.7630\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8795 - val_loss: 0.6435 - val_accuracy: 0.7640\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8797 - val_loss: 0.6501 - val_accuracy: 0.7590\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8805 - val_loss: 0.6486 - val_accuracy: 0.7630\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8799 - val_loss: 0.6544 - val_accuracy: 0.7610\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8823 - val_loss: 0.6466 - val_accuracy: 0.7660\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8844 - val_loss: 0.6508 - val_accuracy: 0.7610\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8845 - val_loss: 0.6467 - val_accuracy: 0.7640\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8847 - val_loss: 0.6443 - val_accuracy: 0.7660\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8863 - val_loss: 0.6464 - val_accuracy: 0.7650\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8872 - val_loss: 0.6465 - val_accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "model_val = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Store the model's `.history` inside of `model_val_dict`\n",
    "* Check what `keys()` this dictionary contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the final results on the training and testing sets using `model.evaluate()` on `train_final` and `label_train_final`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 494us/step - loss: 0.3563 - accuracy: 0.8896\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also use this function to get the results on our testing set.  Call the function again, but this time on `test` and `label_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 553us/step - loss: 0.6210 - accuracy: 0.7633\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the contents of each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35634782910346985, 0.8895999789237976]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train # Expected Results: [0.33576024494171142, 0.89600000000000002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6209511160850525, 0.7633333206176758]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test # Expected Results: [0.72006658554077152, 0.74333333365122478]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results. Let's include the training and the validation loss in the same plot. We'll do the same thing for the training and validation accuracy.\n",
    "\n",
    "Run the cell below to visualize a plot of our training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA59UlEQVR4nO3deXhU5dn48e+dSQhb2EJYA4RFFtkCBDCAEJYW1L4uVEWqIqIivlq31qr1FeJa22pr+am14IJYFa24UAsuIGHRgIRVQHYChH3fyXr//piT6RCyTEImk8ncn+uay5lznnPmPhOce57lPI+oKsYYY0JXWKADMMYYE1iWCIwxJsRZIjDGmBBnicAYY0KcJQJjjAlxlgiMMSbEWSIwFUZE5ojIbeVdtjITkbEistjr9SkRaeNL2TK8l18+MxGZJiLPlvd5TeURHugATOUmIqe8XtYEMoFc5/Xdqvqer+dS1Sv8Uba0RKQB8A4wEDgNvKyqf/LX+3lT1drlcR4RSQbaqeotXuf222dmqjZLBKZY3l9cIpIO3KmqcwuWE5FwVc2pyNguwiNAdaApEAlcGthwjAksaxoyZSIiSSKSISKPisg+4G0RqS8iX4jIQRE56jyP9TomRUTudJ6PFZHFIvKiU3a7iFxRxrKtRWShiJwUkbki8qqI/LOY8HOAA6p6RlWPqup3JVzr6yLyYoFtn4vIw87zx0Rkq/P+60XkumLOpSLSznkeLSKzROSEiPwAtC1Q9m8issvZv1xELne2jwB+D4xymppWF/KZhYnI/4nIDhE5ICLTRaSusy/OieM2EdkpIodE5IniPoMCcd0lIltE5IgTfzNnu4jIX533Oy4ia0Ski7PvSuezOSkiu0Xkt76+n/E/SwTmYjQBGgCtgPG4/z297bxuCZwFXinm+L7ARqAh8CfgTRGRMpR9H/gBiAaSgVtLiPsHYLSIjCuhXL73cX/pCoCI1Ad+Dsxw9m8FLgfqAk8B/xSRpj6c91XgHO6ayTjn4W0ZEI/7M34f+JeIVFfVL4HngQ9Vtbaqdi/k3GOdx2CgDVCbC/8WA4AOwFBgooh0KilgERkC/AG40Yl7B//9HH6Ou7mtPVAPGAUcdva9ibspMQroAnxb0nuZimOJwFyMPGCSqmaq6llVPayqM51f2ieB54BBxRy/Q1Wnqmou7jb7pkDj0pQVkZZAb2Ciqmap6mJgVlFv6PwanwIkAY+JyO3O9kgRycr/1VzAIkBxf9kDXA+kquoeAFX9l6ruUdU8Vf0Q2Az0Kea6EREX8Esn7tOquta5Lg9V/afzmeao6ku4m7E6FHdeLzcDf1HVbap6CngcuElEvJuDn3L+bquB1UBhCaWw876lqitUNdM5b6KIxAHZQBTQERBV/UlV9zrHZQOXikgdpxa2wsfrMBXAEoG5GAdV9Vz+CxGpKSL/cJojTgALgXrOl15h9uU/UdUzztOiOlOLKtsMOOK1DWBXMTHfAXyjqguB4cAzTjK4DFipqscLHqDumRlnAKOdTb8CPJ3kIjJGRFaJyDEROYb7F2/DYmIAiMHdR+cd6w7vAiLyGxH5yWlmOYa7xlHSefM1K3C+Hc77eSfafV7Pz1D0Z1/keZ0kcxhorqrf4q51vArsF5EpIlLHKfpL4Epgh4gsEJFEH6/DVABLBOZiFJy69je4f7H2VdU6uJsJAIpq7ikPe4EGIlLTa1uLYsqH4+4jQFW3AyNwNzW9ATxdzHEfANeLSCvczVQzAZzXU4H7gGhVrQespeRrPujE4R1ry/wnTn/Ao7ibYOo75z3udd6Spg3eg7uJzvvcOcD+Eo4ryXnnFZFauJvkdgOo6mRV7QV0xt1E9IizfZmqXgM0Aj4DPrrIOEw5skRgylMU7n6BY+IeojnJ32+oqjuANCBZRKo5vzT/p5hDPsHd3n+tU1M5gbtZpC3FfLmq6krcX95vAF+p6jFnVy3nuIMATu2iiw9x5zqxJDs1qUsB73sAonB/cR8EwkVkIlDHa/9+IE5Eivp/+APgIacjvTb/7VO42JFd7wO3i0i8iEQ6512qquki0ltE+opIBO5hueeAXOfvcrOI1FXVbNyfeW7Rb2EqmiUCU55eBmoAh4AlwJcV9L43A4m4myieBT7Efb/DBVQ1FXfTziTgKPAVMBt308UHItKjmPf5ABiG+8sw/3zrgZeAVNxfzl2BYkchebkPd3PMPmAa7o72fF8Bc4BNuJtiznF+M9K/nP8eFpHC2tvfAt7F3Ty33Tn+1z7GVSRVnQc8ibtGtBd3Ar3J2V0Hd+3oqBPzYSB/tNWtQLrTZDgBuAVTaYgtTGOqGhH5ENigqn6vkRhTFViNwAQ9p0mirTN2fgRwDe52aGOMD+zOYlMVNMHd3h4NZAD3OG36xhgfWNOQMcaEOGsaMsaYEBd0TUMNGzbUuLi4QIdhjDFBZfny5YdUNaawfUGXCOLi4khLSwt0GMYYE1REZEdR+/zWNCQiLURkvnOL/DoReaCQMiIik52ZDNeISE9/xWOMMaZw/qwR5AC/UdUVIhIFLBeRb5wbcPJdAVziPPoCf3f+a4wxpoL4rUagqnvzZxh0ZqL8CWheoNg1wHR1W4J7gjJfpu81xhhTTiqkj8CZorYHsLTAruacf9t8hrNtr3chERmPe757WrZsiTGmYmVnZ5ORkcG5c+dKLmwCqnr16sTGxhIREeHzMX5PBM6EVzOBB1X1RMHdhRxywY0NqjoF9xzyJCQk2I0PxlSwjIwMoqKiiIuLo+i1g0ygqSqHDx8mIyOD1q1b+3ycX+8jcGYhnAm8p6qfFFIkg/On4Y3FPc2tMaYSOXfuHNHR0ZYEKjkRITo6utQ1N3+OGhLcy9P9pKp/KaLYLGCMM3roMuC414pGxphKxJJAcCjL38mfNYL+uKeeHeKs3rTKWcB6gohMcMrMBrYBW3BPX/u//grmwOkDPPjlg2TmFDo7sTHGhCx/jhparKqiqt1UNd55zFbV11X1daeMquq9qtpWVbuqqt/uFJu6fCp/W/o3rnjvCnLzbE0MY4LJ4cOHiY+PJz4+niZNmtC8eXPP66ysrGKPTUtL4/777y/xPfr161cusaakpPCLX/yiXM5VUYLuzuKySN2VynOLnkMQ5qfPZ+SHI/nsps+sqmtMkIiOjmbVqlUAJCcnU7t2bX7729969ufk5BAeXvjXWUJCAgkJCSW+x/fff18usQajkJh0LiU9hazcLBRFEGZtmsWAtwaweOfiQIdmjCmjsWPH8vDDDzN48GAeffRRfvjhB/r160ePHj3o168fGzduBM7/hZ6cnMy4ceNISkqiTZs2TJ482XO+2rVre8onJSVx/fXX07FjR26++WbyZ2mePXs2HTt2ZMCAAdx///0l/vI/cuQI1157Ld26deOyyy5jzZo1ACxYsMBTo+nRowcnT55k7969DBw4kPj4eLp06cKiRYvK/TMrSkjUCJLikqjmqkZWbhauMBe5ebl8n/E9g6YN4qtbvmJYm2GBDtGYoPHglw+yat+qcj1nfJN4Xh7xcqmP27RpE3PnzsXlcnHixAkWLlxIeHg4c+fO5fe//z0zZ8684JgNGzYwf/58Tp48SYcOHbjnnnsuGHO/cuVK1q1bR7Nmzejfvz/fffcdCQkJ3H333SxcuJDWrVszevToEuObNGkSPXr04LPPPuPbb79lzJgxrFq1ihdffJFXX32V/v37c+rUKapXr86UKVMYPnw4TzzxBLm5uZw5c6bUn0dZhUQiSGyRyLwx80hJT2Hn8Z1MXTEVgDzN44aPbmBcj3Fcf+n1JLZIDHCkxpjSuOGGG3C5XAAcP36c2267jc2bNyMiZGdnF3rMVVddRWRkJJGRkTRq1Ij9+/cTGxt7Xpk+ffp4tsXHx5Oenk7t2rVp06aNZ3z+6NGjmTJlSrHxLV682JOMhgwZwuHDhzl+/Dj9+/fn4Ycf5uabb2bkyJHExsbSu3dvxo0bR3Z2Ntdeey3x8fEX89GUSkgkAnAng8QWiaTuSuWd1e+QlZtFmIRxLPMYf1nyF15Z9gopt6VYMjCmBGX55e4vtWrV8jx/8sknGTx4MJ9++inp6ekkJSUVekxkZKTnucvlIicnx6cyZVnEq7BjRITHHnuMq666itmzZ3PZZZcxd+5cBg4cyMKFC/nPf/7DrbfeyiOPPMKYMWNK/Z5lERJ9BN7yawfPDH6GO3rcQZi4P4Ks3CzGfDqG73eGboeRMcHs+PHjNG/uns5s2rRp5X7+jh07sm3bNtLT0wH48MMPSzxm4MCBvPfee4C776Fhw4bUqVOHrVu30rVrVx599FESEhLYsGEDO3bsoFGjRtx1113ccccdrFixotyvoSghlwjAnQwev/xxxnQfQ6QrkjDnY9hydAuDpg2yTmRjgtDvfvc7Hn/8cfr3709ubvkPEa9RowavvfYaI0aMYMCAATRu3Ji6desWe0xycjJpaWl069aNxx57jHfeeQeAl19+mS5dutC9e3dq1KjBFVdcQUpKiqfzeObMmTzwwAUz9/tN0K1ZnJCQoOW5ME3qrlSSU5KZu30ueZoHQJdGXVh21zKqh1cvt/cxJpj99NNPdOrUKdBhBNypU6eoXbs2qsq9997LJZdcwkMPPRTosC5Q2N9LRJaraqHjaEOyRuAtsUUiyUnJRLoicYmLiLAI1h5YS++pvflu53eBDs8YU4lMnTqV+Ph4OnfuzPHjx7n77rsDHVK5CPkaQb7UXamkpKcQXTOa+2bfR3ZeNuFh4Swcu9A6kE3IsxpBcLEaQRnl9xscPnPY00SUk5fDn777U4AjM8YY/7JEUED+zWcucSEIn2/8nLdWvhXosIwxxm8sERSQP7z0rp53Uc1VDUW5c9adfLvt20CHZowxfmGJoBCJLRJpWbclOXnuG00U5dG5jwY4KmOM8Q9LBEXwbiIKDwsnbW8an234LNBhGROSkpKS+Oqrr87b9vLLL/O//1v0EiZJSUnkDyy58sorOXbs2AVlkpOTefHFF4t9788++4z169d7Xk+cOJG5c+eWIvrCVabpqi0RFMH7DuR5Y+bRrn47bvvsNuZtmxfo0IwJOaNHj2bGjBnnbZsxY4ZPE7+Be9bQevXqlem9CyaCp59+mmHDqtZElf5cqvItETkgImuL2F9XRP4tIqtFZJ2I3O6vWMoqfyRRRFgEu07s4kTmCUa8N4LUXamBDs2YSi91Vyp/WPSHcvn/5frrr+eLL74gM9O9wmB6ejp79uxhwIAB3HPPPSQkJNC5c2cmTZpU6PFxcXEcOnQIgOeee44OHTowbNgwz1TV4L5HoHfv3nTv3p1f/vKXnDlzhu+//55Zs2bxyCOPEB8fz9atWxk7diwff/wxAPPmzaNHjx507dqVcePGeeKLi4tj0qRJ9OzZk65du7Jhw4Ziry/Q01X7s0YwDRhRzP57gfWq2h1IAl4SkWp+jKfMUtJTPP0FOXk5fLTuowBHZEzllrorlaHTh/Lk/CcZOn3oRSeD6Oho+vTpw5dffgm4awOjRo1CRHjuuedIS0tjzZo1LFiwwPMlWpjly5czY8YMVq5cySeffMKyZcs8+0aOHMmyZctYvXo1nTp14s0336Rfv35cffXV/PnPf2bVqlW0bdvWU/7cuXOMHTuWDz/8kB9//JGcnBz+/ve/e/Y3bNiQFStWcM8995TY/JQ/XfWaNWt4/vnnPZPN5U9XvWrVKhYtWkSNGjV4//33GT58OKtWrWL16tXlMkupP5eqXAgcKa4IEOUscl/bKXvhNICVgHd/AcDCHQvLNBOhMaEifzGoXM0lKzeLlPSUiz6nd/OQd7PQRx99RM+ePenRowfr1q07rxmnoEWLFnHddddRs2ZN6tSpw9VXX+3Zt3btWi6//HK6du3Ke++9x7p164qNZ+PGjbRu3Zr27dsDcNttt7Fw4ULP/pEjRwLQq1cvz0R1RVm8eDG33norUPh01ZMnT+bYsWOEh4fTu3dv3n77bZKTk/nxxx+Jiooq9ty+CGQfwStAJ2AP8CPwgKpzJ1cBIjJeRNJEJO3gwYMVGSNwfn/BTZ1vYsW+FbyU+lKFx2FMsPD+8VTNVY2kuKSLPue1117LvHnzWLFiBWfPnqVnz55s376dF198kXnz5rFmzRquuuoqzp07V+x5ilqiduzYsbzyyiv8+OOPTJo0qcTzlPRjMH8q66Kmui7pXPnTVb/xxhucPXuWyy67jA0bNnimq27evDm33nor06dPL/bcvghkIhgOrAKaAfHAKyJSp7CCqjpFVRNUNSEmJqbiIvSS2CKRpLgkPt/4OQC/++Z3NkupMUUoONiiPKZpqV27NklJSYwbN85TGzhx4gS1atWibt267N+/nzlz5hR7joEDB/Lpp59y9uxZTp48yb///W/PvpMnT9K0aVOys7M9U0cDREVFcfLkyQvO1bFjR9LT09myZQsA7777LoMGDSrTtQV6uupALkxzO/CCulPhFhHZDnQEfghgTMXKr+6C+96CyUsnM6DlgABHZUzllL8YVHkaPXo0I0eO9DQRde/enR49etC5c2fatGlD//79iz2+Z8+ejBo1ivj4eFq1asXll1/u2ffMM8/Qt29fWrVqRdeuXT1f/jfddBN33XUXkydP9nQSA1SvXp23336bG264gZycHHr37s2ECRPKdF3JycncfvvtdOvWjZo1a543XfX8+fNxuVxceumlXHHFFcyYMYM///nPREREULt27XKpEfh10jkRiQO+UNUuhez7O7BfVZNFpDGwAuiuqoeKO6e/Jp3zRX4HWFZuFnmaR+PajUl/IJ3I8MiSDzYmiNmkc8GltJPO+a1GICIf4B4N1FBEMoBJQASAqr4OPANME5EfAQEeLSkJBJr32sc1Imrw0FcPMWX5FH7d99eBDs0YY8rMb4lAVYu900NV9wA/99f7+0t+dVdVeWf1Ozzx7RN0a9yNQXFlaxs0xphAszuLy2hJxhJ+OvgTJ7NO8rN3f2Y3mZkqz4ZMB4ey/J0sEZSR901m2XnZzNtuU0+Yqqt69eocPnzYkkElp6ocPnyY6tVLt8xuIEcNBbX8cdKZuZnkaZ5nNJExVVFsbCwZGRkE4j4eUzrVq1cnNja2VMfYUpUXIXVXKvPT5/P2yrcJd4Wz9p61uMJcgQ7LGGMuYEtV+klii0R+f/nvuS3+NjYc2sCfv/tzoEMyxphSs0RwkVJ3pfL8oucBeGL+E9ZpbIwJOpYILpL33cZ5mse7a94NcETGGFM6lgguUsGZSTce2ljCEcYYU7nYqKGL5H238bqD6/hg7QdsP7qd1vVbBzo0Y4zxidUIykH+SmYvDHuBMAnjb0v/FuiQjDHGZ5YIylFsnViGxA3h72l/Z+62i1/c2hhjKoIlgnKUuiuVBTsWkJWbxZXvXWkjiIwxQcESQTkqOO3E/PT5AY7IGGNKZomgHOWPIApzPtZaEbUCHJExxpTMEkE5yh9BlJyUTP3q9W0iOmNMUPDnwjRvAb8ADhS2QplTJgl4GfeCNYdUNegn9c9fryArN4vnFj3HtqPbaFO/TaDDMsaYIvmzRjANGFHUThGpB7wGXK2qnYEb/BhLhZuQMAFBGPvZWOs0NsZUan5LBKq6EDhSTJFfAZ+o6k6n/AF/xRIIO4/vRERYtHMRQ6cPtWRgjKm0AtlH0B6oLyIpIrJcRMYUVVBExotImoikBct86CnpKZ5FPDJzMklJTwlsQMYYU4RAJoJwoBdwFTAceFJE2hdWUFWnqGqCqibExMRUZIxllhSXRGR4pPuFuF8bY0xlFMhEkAF8qaqnVfUQsBDoHsB4ylX+CKJfXPIL8jSPaq5qgQ7JGGMKFchE8DlwuYiEi0hNoC/wUwDjKXeJLRJ5d+S71IyoyWvLXgt0OMYYUyi/JQIR+QBIBTqISIaI3CEiE0RkAoCq/gR8CawBfgDeUNW1/oonUOpVr8ew1sOYvmY6X2/9OtDhGGPMBWzNYj9L3ZXK4HcGk5mbSURYBAvGLiCxRWKgwzLGhBhbsziAbP4hY0xlZ4nAzwrOP1Qvsl5gAzLGmAIsEfhZ/uihiUkTqV2tNot2LQp0SMYYcx5bqrIC5M8/dPTsUV5b9hr7h++nce3GgQ7LGGMAqxFUqAkJE8jOy2bMp2NsygljTKVhiaACHT17lDAJ4+ttX9v8Q8aYSsMSQQVKSU8BZ7RuZq7NP2SMqRwsEVSg8+YfwuYfMsZUDpYIKlD+CKKkVkmoKs3rNA90SMYYY4mgoiW2SGTatdMAmLp8amCDMcYYLBEERKt6rbiq/VW8sfINsnOzAx2OMSbEWSIIkEGtBrHv1D7+9N2fAh2KMSbEWSIIgNRdqUycPxGAiSkTbRipMSagLBEEQEp6Clm5WQDkaR4frfsowBEZY0KZJYIAyJ+IziUuAHaf2B3giIwxoczmGgqA/GGkKekpzE+fz9fbvuZ01mlqVasV6NCMMSHInyuUvSUiB0Sk2FXHRKS3iOSKyPX+iqUySmyRyOOXP86TA5/keOZxPlj7QaBDMsaEKH82DU0DRhRXQERcwB+Br/wYR6U2oOUA2tRvw8T5E/l+5/eBDscYE4L8lghUdSFwpIRivwZmAgf8FUdltyRjCbuO72Lvqb0MmT7ERhAZYypcwDqLRaQ5cB3wug9lx4tImoikHTx40P/BVaCU9BTyNA+ArNwsm4jOGFPhAjlq6GXgUVXNLamgqk5R1QRVTYiJifF/ZBUofwSRIChK18ZdAx2SMSbEBDIRJAAzRCQduB54TUSuDWA8AZE/guihyx4CYOXelQGOyBgTagI2fFRVW+c/F5FpwBeq+lmg4gmk/KUs1x1cx+vLX+exAY8R4YoIdFjGmBDhz+GjHwCpQAcRyRCRO0RkgohM8Nd7BrthbYax5+QeXlj8QqBDMcaEEFHVQMdQKgkJCZqWlhboMMpd6q5Uhk4fytmcs4RJGItvX0xii8RAh2WMqSJEZLmqJhS2z6aYqCQKzj/07pp3AxyRMSZUWCKoJArOP7TlyJYAR2SMCRU211Al4T3/0Or9q5n500x2n9hty1kaY/zOagSVSP78Q38Y+gdy83K5+ZOb7U5jY4zfWSKohPad2keYhLFgxwKGTh9qycAY41eWCCqhlPQUFPdorsycTJt2whjjV5YIKqGkuCQiXZEAKMqAVgMCHJExpiqzRFAJ5Xcc39L1FhS1FcyMMX5liaCSSmyRyDvXvUPLOi35zde/sbUKjDF+Y4mgEluasZS9p/ay5+QeW6vAGOM3lggqMe+1CjJzrdPYGOMflggqMe+1CgCia0YHOCJjTFVkiaASy+80njhoIlHVovhi0xeBDskYUwXZFBOVXP5aBWESxqSUSTww5wFu6nKTzUxqjCk3ViMIEn2b9wVg8g+T7W5jY0y5skQQJFbsXeHpK7BF7o0x5cmnRCAitUQkzHneXkSuFpFi11IUkbdE5ICIrC1i/80issZ5fC8i3UsffuhIiksiMjzyvNfGGFMefK0RLASqi0hzYB5wOzCthGOmASOK2b8dGKSq3YBngCk+xhKSElsk8u2YbxkcN5hczaVmRM1Ah2SMqSJ8TQSiqmeAkcD/U9XrgEuLO0BVFwJHitn/vaoedV4uAWJ9jCVkJbZIZOaNM6kTWYf7v7yfPyz6g/UVGGMumq+jhkREEoGbgTtKeawv7gDmFPPm44HxAC1btizHtw0+9WvU54ZON/DmqjdZvHMxka5I5o2ZZ6OIjDFl5muN4EHgceBTVV0nIm2A+eURgIgMxp0IHi2qjKpOUdUEVU2IiYkpj7cNavmrluVpnnUcG2Mumk+JQFUXqOrVqvpHp9P4kKref7FvLiLdgDeAa1T18MWeL1SMaDeCiDB3X314WLh1HBtjLoqvo4beF5E6IlILWA9sFJFHLuaNRaQl8Alwq6puuphzhZrEFol8c+s31IusR6t6regb2zfQIRljgpivTUOXquoJ4FpgNtASuLW4A0TkAyAV6CAiGSJyh4hMEJEJTpGJQDTwmoisEpG0Ml1BiBoUN4jJV0xm0+FN/Grmr6zT2BhTZr52+EY49w1cC7yiqtkiosUdoKqjS9h/J3Cnj+9vCtG6fmsE4cN1HzJr4yzrNDbGlImvNYJ/AOlALWChiLQCTvgrKOObRTsWee42PpdzzjqNjTFl4mtn8WRVba6qV6rbDmCwn2MzJfC+21hRujbuGuCIjDHByNfO4roi8hcRSXMeL+GuHZgAyp+m+uHLHsYlLv6R9g+7ycwYU2q+9hG8BawFbnRe3wq8jftOYxNA+dNU7zu1j/fXvs/sLbPtJjNjTKn42kfQVlUnqeo25/EU0MafgZnSadegHWA3mRljSs/XRHBWRAbkvxCR/sBZ/4RkymJEuxFUc1UDIEzC7CYzY4zPfE0EE4BXRSRdRNKBV4C7/RaVKbXEFonMHzOf1vVaExEWwX82/8f6CowxPvF11NBqVe0OdAO6qWoPYIhfIzOl1q9lP54d8ixncs7w/KLnbSUzY4xPSrVCmaqecO4wBnjYD/GYi7Tj2A4EQVEyczOtr8AYU6KLWapSyi0KU26S4pKoHl4dAFWldrXaNqTUGFMsUS12poiiDxTZqaoVvjhAQkKCpqXZtETFSd2Vytur3mbqiqmEh4WjqlRzVbMhpcaEMBFZrqoJhe0r9j4CETkJFJYpBKhRDrEZP8i/t2D1vtX8sOcH4L8L3lsiMMYUVGzTkKpGqWqdQh5RqlqeK5QZP3hu6HOeuYhcYS52Ht9pTUTGmAtcTB+BqeSGtRnG5CsmA5CTl8PUFVNtJJEx5gKWCKq4+/rcx4CWA8jTPHI11+46NsZcwBJBCHh28LOeJqIIVwTRNaNtJJExxsNviUBE3hKRAyKytoj9IiKTRWSLiKwRkZ7+iiXUDYobxPTrphMeFk7req158MsHeXL+k9ZMZIwB/FsjmAaMKGb/FcAlzmM88Hc/xhLybul2C69d+Ro/HfqJcznnrJnIGOPht0SgqguBI8UUuQaY7ix0swSoJyJN/RWPgTt73smwNsNQlDAJs5FExhggsH0EzYFdXq8znG0XEJHx+YviHDx4sEKCq4pEhJk3zqR5VHOqu9x3H9tIImNMIBNBYVNUFHqbs6pOUdUEVU2IiYnxc1hVW53IOsy5eQ7Zedlk5WZZE5ExJqCJIANo4fU6FtgToFhCStfGXXni8icAEIRqrmo2ksiYEBbIu4NnAfeJyAygL3BcVfcGMJ6QMilpEusPruej9R9xU5ebePDLB8nKzbI5iYwJQX5LBCLyAZAENBSRDGASEAGgqq8Ds4ErgS3AGeB2f8ViCvfPkf/k4JmDTF89HUU9y1xOXz2dlPQUkuKSLCEYEwLKPPtooNjso+Xr8JnDdH+9O7tP7sYlLlxhLgQhJy/HagfGVCHFzT5qdxaHuOia0Xxz6zfUjKhJTK0Ybul6Czl5OeRqLpk5mSSnJFu/gTFVnCUCQ6eYTnw66lMOnTnEmgNrqOaqRhhh5JHH3O1zbXipMVWcJQIDwM/b/pyp/zOVtD1pJMUlMazNMMIkzNNvYMNLjam6LBEYj7HxY3kq6SnmbJlDo1qNiHRF4hKXDS81poqzxWXMeZ4c+CR7T+7l9eWvc2/CvTSv05zomtE2vNSYKsxqBOY8IsIrV77CqM6jeDXtVWJqxXD4zGHPXcjWgWxM1WOJwFzAFeZi+nXTGdFuBOP/PZ5zOeesA9mYKswSgSlUNVc1Zt44k6S4JJ5d9CyPDXjsgg7k6aunW7+BMVWAJQJTpJoRNfn36H8zoOUAnl7wNANaDvB0ILvCXLy96m1b4MaYKsASgSlWrWq1+GL0F/Rr0Y/kBck8dNlDPDP4GcbFj7Mbz4ypIiwRmBJFRUYx5+Y5DG09lOcXP09UZBRjuo8ptN9gyvIp1lxkTJCxuYaMzzJzMhn18Sg+3/g5Tyc9zdDWQ3lqwVPM3T6XPM0jDPeqZ3maZ8NMjalkbK4hUy4iwyP51w3/Ykz3MUxMmciH6z5k4qCJnn6DsLAwcjXXmouMCTJ2Q5kplQhXBG9f8zbRNaL565K/su/0Pmb/ajapGameG88yczI9zUWLdi7i5REvc/jMYZvW2phKyhKBKbUwCeOln79Ek9pNeHTuo+w8vpPPb/qcRrUa0bVRV5JTkj3NRZk5mdw3+z5rLjKmEvNr05CIjBCRjSKyRUQeK2R/XRH5t4isFpF1ImKL0wQJEeF3/X/Hxzd8zOp9q+n7Rl9+3P8jiS0SSU5KLrS5yO49MKZy8ltnsYi4gE3Az3CvT7wMGK2q673K/B6oq6qPikgMsBFooqpZRZ3XOosrn2W7l3HNjGs4kXmCf478J9d2vJbUXamkpKecN0+R96I3rjAX4+LHMab7GKshGFMBiuss9mciSASSVXW48/pxAFX9g1eZx3EvYH8vEAd8A7RX1byizmuJoHLafWI31314Hcv2LOOppKf4v4H/R5i4K5z5SWHn8Z1MXTGVXM0FQBCqh1e3PgRjKkCgEsH1wAhVvdN5fSvQV1Xv8yoThXsR+45AFDBKVf9T3HktEVReZ7PPcvcXd/Pumne56pKrePe6d6lfo75nf+quVIZOH8q5nHMo7n93NuTUmIoRqOGjUsi2gllnOLAKaAbEA6+ISJ0LTiQyXkTSRCTt4MGD5R2nKSc1ImrwzrXv8MoVr/D11q/pNaUXy3Yv8+xPbJHIvDHzuLvX3SUOOU3dlWp9CcZUkEA3Df0HeEFVFzmvvwUeU9Ufijqv1QiCw5KMJdz4rxvZe2ovzw95nt/0+42nqQi4oA8hf8hpmIQRHhZufQnGlLNANQ2F4+4sHgrsxt1Z/CtVXedV5u/AflVNFpHGwAqgu6oeKuq8lgiCx9GzRxn/xXg+Xv8xQ1sP5a1r3qJl3ZYXlEvdlXrekFNxKpP5zUfWl2DMxQtIInDe+ErgZcAFvKWqz4nIBABVfV1EmgHTgKa4m5JeUNV/FndOSwTBRVV5c+WbPPTVQwjCX4f/lXE9xiFyfsthfv+B9+iirNysIvsSLCkYUzoBSwT+YIkgOG0/up1xs8aRkp7C8LbDmfo/U2lRt8V5ZfKbi5LikgCYvno6b696m5y8HESEPM27YE4j76YjwHO8JQdjzmeJwFQKeZrHqz+8ymPzHsMlLl78+Yvc2fPO8/oOCirsfgTvpADupqMIV4T1KxhTDEsEplLZdnQbd8y6g5T0FPo278urV75Kr2a9SjyuYFLwHoZaUr9CdM1oa0oyIc0Sgal0VJV317zL7775HQdOH+Cunnfx7JBniakV49PxqbtSz2s6Kq5fITcv1zMiKdIVaf0LJiRZIjCV1vFzx0lOSeaVZa9QK6IWkwZN4t4+91LNVc2n433tV8hn/QsmVFkiMJXehkMbeOirh/hyy5e0a9COPw37E9d2vPaC0UW+KO4ehTAJK7Z/wXtEkndzEliiMMHNEoEJGl9u+ZLffP0b1h9cT78W/Xh28LMMbj24zOfzTgr5X+7F9S8U1pxU1A1uYMnBBA9LBCao5OTl8OaKN3l64dPsObmHIa2HMGnQJAa2Glgu5y+qf6Go5qTCOqKLGqUElhxM5WSJwASls9ln+cfyf/DC4hfYf3o/A1sN5InLn+BnbX5Wpiajggr2L5Q05YV3R3RZk4P3+1iHtalIlghMUDubfZapK6byx+/+yJ6Te+jeuDu/7fdbRnUeRYQrotzfr2BzUmEd0YWNUvIlOQhCdm52oaOYCuuTsH4KU14sEZgqITMnk/d/fJ8XU19k/cH1xNaJ5YG+DzC+13jqRF4waa1fFDdKqaTkUDBRQOFDXPNrIN4Jw5d+ivznhdU2vOO2JBKaLBGYKkVVmbNlDi9+/yLz0+cTVS2K8b3Gc3/f+wud1M7ffEkORdUICo5iggtrFoVtK01tY+XelZ54ShoVVVINxNeEYomn8rFEYKqs5XuW81LqS3y07iMArmp/FWO7j+Wq9lf5fC+CPxTW/1DYF25xfRKF1QjKUtvIycsp9ia7kmog+cnD14TinQh9GY5b8DMpKnkU1WRX2OdcMHH52idTVAK7mPMUdn1luf6LZYnAVHk7j+/ktWWvMX31dPae2kvDmg25Pf52xvcaT7sG7QIdXrGK+4LzpZ/C19qGIJ6b6UpTAyltQinp7u6CzVy+9Jv4sm5FwaazHk17XHBMcX0yxSWwsp6nsOsry/WXRx+RJQITMnLycvh669e8ufJNPt/wObmay6BWgxjTfQzXX3p9hfUl+FNpaxv5U3sX9eVYUo2gsEn+fEkovpTztd+kpCY0X9+7tAksT/OKvUO9pPOUlGRL22+Un6TKsqSrJQITkvac3MNbK99i+urpbD6ymRrhNbiu03Xc1v02hrYeiivMFegQ/a6wpo7S1EAKzvzqS0Ip6Vd5Sb+IC/vS97VmUVJtxJc+mYJJ5GLOk9+PU5oaQUnndomLZwY/w+OXP16qfwuWCExIU1WW7l7KO6veYca6GRw7d4wmtZtw46U3MrrraPo271su9yVUZaVNKKUpl/+8uGYgX5pLoOT+CV+XRs1PYFm5WRd1Hu+RXRdz/UFdIxCREcDfcK9Q9oaqvlBImSTcq5hFAIdUdVBx57REYC7GuZxz/Hvjv/lg7QfM3jybzNxM4urFceOlN3Jj5xvp2bSnJYVKoLSds4UdW9ZOZ19HSPl6nrLwx7kDtWaxC/eaxT8DMnCvWTxaVdd7lakHfA+MUNWdItJIVQ8Ud15LBKa8HD93nM82fMaH6z7km23fkJOXQ6u6rRjZaSQjO40kMTYxJJqPTGgIVCJIBJJVdbjz+nEAVf2DV5n/BZqp6v/5el5LBMYfDp85zKyNs/hkwyd8vfVrsnKzaFSrEdd0uIZrOlzD0DZDqR5ePdBhGlNmgUoE1+P+pX+n8/pWoK+q3udV5mXcTUKdgSjgb6o6vZBzjQfGA7Rs2bLXjh07/BKzMQAnMk8wZ/McPtnwCbM3z+ZU1ilqRdRicOvBDG87nBHtRlT6IanGFFRcIgj35/sWsq1g1gkHegFDgRpAqogsUdVN5x2kOgWYAu4agR9iNcajTmQdRnUZxaguo8jMySQlPYVZG2fx1dav+GLTFwB0adSFX3b6JVd3uJoeTXpYv4IJav5MBBlAC6/XscCeQsocUtXTwGkRWQh0x923YEzARYZHMrzdcIa3Gw7A1iNb+WLTF3yy4ROeXvA0Ty14iqa1m3JFuysY2mYoQ1oPoUntJgGO2pjS8WfTUDjuL/ShwG7cncW/UtV1XmU6Aa8Aw4FqwA/ATaq6tqjzWh+BqSwOnD7AnM1zmL1lNl9v/Zpj544B0KlhJwbHDWZw68EMjhtMdM3owAZqDIEdPnol7qGhLuAtVX1ORCYAqOrrTplHgNuBPNxDTF8u7pyWCExllJuXy8p9K5m3bR4pO1JYtGMRp7NPIwg9mvZgSNwQBrYaSP+W/WlQo0GgwzUhyG4oM6aCZedms2zPMuZtm8fc7XNZkrGErNwsBKFb424kxSUxOG4wg+IGUa96vUCHa0KAJQJjAuxczjl+2P0DC9IXsGDHAr7b9R3ncs4RJmH0atqLpLgkd42hRX/q16gf6HBNFWSJwJhKJjMnk6W7l/Lt9m/5dvu3LN291FNj6NKoC/1b9Kdfi370je3LJQ0usVFJ5qJZIjCmksuvMSzcsZDFOxfz/a7vOZl1EoD61evTp3kfLou9jD7N+5DQLIFGtRoFOGITbCwRGBNkcvNyWX9wPUt3L2VJxhKW7l7KugPrPDNbtqrbistbXc6gVoMY0HIA7aPbEyZhAY7aVGaWCIypAk5mnmTF3hWk7Uljye4lLEhfwMEzBwGIqhZFz6Y96dO8D32b96VP8z7E1om1JiXjYYnAmCpIVdlwaANLdy8lbU8ay/YsY9W+VWTlZgHQqFYjejXtRe9mvekb25fezXoTUysmwFGbQLFEYEyIyMzJZNW+VSzbs4zle5eTtieN9QfXexY5aVSrEZ1jOtO9cXd6NetFQrMEOkR3sJpDCLBEYEwIO5V1irQ9aazYu4J1B9ax7uA61uxfw9mcswA0qNGAfi36kdA0gc6NOtM5pjPto9vbFNxVjCUCY8x5cvJy2HBoAz/s/oHvd33Pd7u+Y+OhjZ7O6BrhNejWuBvxTeLp3rg73Rp3o1vjbkRFRgU4clNWlgiMMSU6k32GDYc2sPbAWlbuXcnKfStZvX+1Zw4lQbgk+hK6N+7OpTGXcmnMpcQ3iaddg3Y2YikIWCIwxpSJqpJxIoNV+1axat8qVuxbwZr9a9h+dLun9lAnsg49mvTw1Bw6xXSiXYN2xNSMsb6HSsQSgTGmXJ3NPsuGQxtYsXcFy/cuZ8XeFaw9sJbT2ac9ZepE1qF74+7EN4mnS6MutI9uT/vo9jSt3dQSRABYIjDG+F2e5rHt6DY2Hd7EliNb2HhoI6v3r2b1/tWcyjrlKVcnsg4dG3b0jF7q3qQ7XRp1oWHNhgGMvuqzRGCMCZg8zSPjRAabDm9i46GN/HToJ9YfXM/aA2s9N8SBe2jrpTGX0iG6A+2j29M5pjPdGnejSe0mVoMoB5YIjDGVjqqy//R+Vu9bzbqD61h7YC3rD65n0+FNHD131FOuQY0GdIjuQIeGHWjfoD0dGnagQ3QH4urFUatarQBeQXCxRGCMCSqHzhxi7YG1/Lj/R9YeWMumI+7axN5Te88rF1Mzhk4xnUhomkDPpj2JqxdH8zrNaR7VnAhXRICir5wCuULZCOBvuFcoe0NVXyiiXG9gCTBKVT8u7pyWCIwJXSczT7Lp8CY2Hd5E+rF0th3dxtqDa1m1bxXncs55yrnERZv6bejYsKPn0T66Pa3qtqJZVLOQvFmuuETgt8XrRcQFvAr8DPci9ctEZJaqri+k3B+Br/wVizGmaoiKjKJXs170atbrvO3ZudlsOryJXSd2sfvEbrYd3cbGwxvZcGgDX239yjP/EkB4WDiXNLiEro270jmmM5c0uIR2DdrRtkHbkF1G1G+JAOgDbFHVbQAiMgO4BlhfoNyvgZlAbz/GYoypwiJcEe7pMRp1vmBfbl4u6cfS2XxkMzuO7SD9WDrrD60nbU8aH6376Lyy9avXp22DtrSt7zwatHUnifptaRrVtMreOOfPRNAc2OX1OgPo611ARJoD1wFDKCYRiMh4YDxAy5Ytyz1QY0zV5Qpzub/cG7S9YN/Z7LNsO7qNLUe2sPXoVrYc2cLmI5tZtmcZH6//mFzN9ZSNdEUSVy+ONvXb0KZ+G9rWdyeJdg3a0aZ+GyLDIyvyssqVPxNBYeO9CnZIvAw8qqq5xQ0PU9UpwBRw9xGUV4DGmNBWI6JGkTWJ7Nxsdh7fydajW9l6ZCvbjm5j27FtbD+6ne92fceJzBOesoIQWyeWtg3a0qZeG+LqxRFXL86TKBrWbFiph8D6MxFkAC28XscCewqUSQBmOB9QQ+BKEclR1c/8GJcxxpQowhXx35pEgcqEqnLk7BG2Ht3K5sObPTWKrUe3MmfLnAtGN0VVi6JN/Ta0rt+a5lHuUU2xdWJpUbcFLeq0oGXdlgEd5eTPRLAMuEREWgO7gZuAX3kXUNXW+c9FZBrwhSUBY0xlJyJE14wmumY0fZr3uWD/uZxzpB9LZ8uRLWw5soVtR7ex/dh2Nh/eTEp6imciv3wucXmaneLqxdGqbita1Wvled40qinhYf77uvbbmVU1R0Tuwz0ayAW8parrRGSCs/91f723McYEUvXw6p5hq4U5nXWa3Sd3s+v4LnYe3+nupzi6ha1HtvL5xs85cPrAeeVd4iK2Tiz3972fhxMfLvd4/VkjQFVnA7MLbCs0AajqWH/GYowxlUWtarU8k/AV5kz2GXYe30n6sXR2HNvBzuM72XliJ01qN/FLPH5NBMYYY0qvZkTNYmsU5a1qDoo1xhjjM0sExhgT4iwRGGNMiLNEYIwxIc4SgTHGhDhLBMYYE+IsERhjTIizRGCMMSEu6JaqFJGDwI5SHtYQOOSHcALBrqVysmupvKrS9VzMtbRS1ZjCdgRdIigLEUkraom2YGPXUjnZtVReVel6/HUt1jRkjDEhzhKBMcaEuFBJBFMCHUA5smupnOxaKq+qdD1+uZaQ6CMwxhhTtFCpERhjjCmCJQJjjAlxVToRiMgIEdkoIltE5LFAx1MaItJCROaLyE8isk5EHnC2NxCRb0Rks/Pf+oGO1Vci4hKRlSLyhfM6mK+lnoh8LCIbnL9RYrBej4g85PwbWysiH4hI9WC5FhF5S0QOiMhar21Fxi4ijzvfBxtFZHhgoi5cEdfyZ+ff2BoR+VRE6nntK7drqbKJQERcwKvAFcClwGgRuTSwUZVKDvAbVe0EXAbc68T/GDBPVS8B5jmvg8UDwE9er4P5Wv4GfKmqHYHuuK8r6K5HRJoD9wMJqtoF9/riNxE81zINGFFgW6GxO///3AR0do55zfmeqCymceG1fAN0UdVuwCbgcSj/a6myiQDoA2xR1W2qmgXMAK4JcEw+U9W9qrrCeX4S9xdNc9zX8I5T7B3g2oAEWEoiEgtcBbzhtTlYr6UOMBB4E0BVs1T1GEF6PbiXrK0hIuFATWAPQXItqroQOFJgc1GxXwPMUNVMVd0ObMH9PVEpFHYtqvq1quY4L5cAsc7zcr2WqpwImgO7vF5nONuCjojEAT2ApUBjVd0L7mQBNApgaKXxMvA7IM9rW7BeSxvgIPC209T1hojUIgivR1V3Ay8CO4G9wHFV/ZogvBYvRcUe7N8J44A5zvNyvZaqnAikkG1BN1ZWRGoDM4EHVfVEoOMpCxH5BXBAVZcHOpZyEg70BP6uqj2A01TeppNiOe3n1wCtgWZALRG5JbBR+U3QfieIyBO4m4vfy99USLEyX0tVTgQZQAuv17G4q7xBQ0QicCeB91T1E2fzfhFp6uxvChwIVHyl0B+4WkTScTfRDRGRfxKc1wLuf1sZqrrUef0x7sQQjNczDNiuqgdVNRv4BOhHcF5LvqJiD8rvBBG5DfgFcLP+98avcr2WqpwIlgGXiEhrEamGu2NlVoBj8pmICO426J9U9S9eu2YBtznPbwM+r+jYSktVH1fVWFWNw/13+FZVbyEIrwVAVfcBu0Skg7NpKLCe4LyencBlIlLT+Tc3FHd/VDBeS76iYp8F3CQikSLSGrgE+CEA8flMREYAjwJXq+oZr13ley2qWmUfwJW4e9q3Ak8EOp5Sxj4Ad1VvDbDKeVwJROMeCbHZ+W+DQMdayutKAr5wngfttQDxQJrz9/kMqB+s1wM8BWwA1gLvApHBci3AB7j7NrJx/0q+o7jYgSec74ONwBWBjt+Ha9mCuy8g/zvgdX9ci00xYYwxIa4qNw0ZY4zxgSUCY4wJcZYIjDEmxFkiMMaYEGeJwBhjQpwlAmMcIpIrIqu8HuV2t7CIxHnPKmlMZRIe6ACMqUTOqmp8oIMwpqJZjcCYEohIuoj8UUR+cB7tnO2tRGSeM1f8PBFp6Wxv7Mwdv9p59HNO5RKRqc7c/1+LSA2n/P0ist45z4wAXaYJYZYIjPmvGgWahkZ57Tuhqn2AV3DPpIrzfLq654p/D5jsbJ8MLFDV7rjnIFrnbL8EeFVVOwPHgF862x8DejjnmeCfSzOmaHZnsTEOETmlqrUL2Z4ODFHVbc5EgPtUNVpEDgFNVTXb2b5XVRuKyEEgVlUzvc4RB3yj7sVSEJFHgQhVfVZEvgRO4Z6q4jNVPeXnSzXmPFYjMMY3WsTzosoUJtPreS7/7aO7Cvdqer2A5c4CMcZUGEsExvhmlNd/U53n3+OeTRXgZmCx83wecA941mmuU9RJRSQMaKGq83Ev3FMPuKBWYow/2S8PY/6rhois8nr9parmDyGNFJGluH88jXa23Q+8JSKP4F6x7HZn+wPAFBG5A/cv/3twzypZGBfwTxGpi3uxkb+qe9lLYyqM9REYUwKnjyBBVQ8FOhZj/MGahowxJsRZjcAYY0Kc1QiMMSbEWSIwxpgQZ4nAGGNCnCUCY4wJcZYIjDEmxP1/9JmSwxo8UmMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss_values = model_val_dict['loss']\n",
    "val_loss_values = model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g.', label='Validation loss')\n",
    "\n",
    "plt.title('Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! \n",
    "\n",
    "Run the cell below to visualize a plot of our training and validation accuracy>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc_values = model_val_dict['accuracy'] \n",
    "val_acc_values = model_val_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r.', label='Validation acc')\n",
    "plt.title('Training & validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a status quo around the 60th epoch. This means that we're actually **overfitting** to the train data when we do as many epochs as we were doing. Luckily, you learned how to tackle overfitting in the previous lecture! For starters, it does seem clear that we are training too long. So let's stop training at the 60th epoch first (so-called \"early stopping\") before we move to more advanced regularization techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Early stopping\n",
    "\n",
    "Now that we know that the model starts to overfit around epoch 60, we can just retrain the model from scratch, but this time only up to 60 epochs! This will help us with our overfitting problem.  This method is called **_Early Stopping_**.\n",
    "\n",
    "In the cell below: \n",
    "\n",
    "* Recreate the exact model we did above. \n",
    "* Compile the model with the exact same hyperparameters.\n",
    "* Fit the model with the exact same hyperparameters, with the exception of `epochs`.  This time, set epochs to `60` instead of `120`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9431 - accuracy: 0.1823 - val_loss: 1.9276 - val_accuracy: 0.2130\n",
      "Epoch 2/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.9152 - accuracy: 0.2111 - val_loss: 1.9019 - val_accuracy: 0.2420\n",
      "Epoch 3/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8887 - accuracy: 0.2299 - val_loss: 1.8752 - val_accuracy: 0.2530\n",
      "Epoch 4/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8602 - accuracy: 0.2529 - val_loss: 1.8468 - val_accuracy: 0.2760\n",
      "Epoch 5/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8277 - accuracy: 0.2780 - val_loss: 1.8153 - val_accuracy: 0.2950\n",
      "Epoch 6/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7915 - accuracy: 0.3097 - val_loss: 1.7799 - val_accuracy: 0.3160\n",
      "Epoch 7/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7519 - accuracy: 0.3337 - val_loss: 1.7397 - val_accuracy: 0.3480\n",
      "Epoch 8/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7097 - accuracy: 0.3633 - val_loss: 1.6990 - val_accuracy: 0.3720\n",
      "Epoch 9/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.6648 - accuracy: 0.3892 - val_loss: 1.6527 - val_accuracy: 0.3980\n",
      "Epoch 10/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6172 - accuracy: 0.4165 - val_loss: 1.6056 - val_accuracy: 0.4180\n",
      "Epoch 11/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5676 - accuracy: 0.4441 - val_loss: 1.5587 - val_accuracy: 0.4430\n",
      "Epoch 12/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5171 - accuracy: 0.4704 - val_loss: 1.5086 - val_accuracy: 0.4670\n",
      "Epoch 13/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4664 - accuracy: 0.4929 - val_loss: 1.4592 - val_accuracy: 0.5000\n",
      "Epoch 14/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4162 - accuracy: 0.5243 - val_loss: 1.4124 - val_accuracy: 0.5200\n",
      "Epoch 15/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3667 - accuracy: 0.5507 - val_loss: 1.3653 - val_accuracy: 0.5440\n",
      "Epoch 16/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3186 - accuracy: 0.5739 - val_loss: 1.3213 - val_accuracy: 0.5520\n",
      "Epoch 17/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2722 - accuracy: 0.5965 - val_loss: 1.2770 - val_accuracy: 0.5730\n",
      "Epoch 18/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.6165 - val_loss: 1.2367 - val_accuracy: 0.5870\n",
      "Epoch 19/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1841 - accuracy: 0.6367 - val_loss: 1.1963 - val_accuracy: 0.5980\n",
      "Epoch 20/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1426 - accuracy: 0.6535 - val_loss: 1.1593 - val_accuracy: 0.6290\n",
      "Epoch 21/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1030 - accuracy: 0.6695 - val_loss: 1.1237 - val_accuracy: 0.6250\n",
      "Epoch 22/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0659 - accuracy: 0.6813 - val_loss: 1.0912 - val_accuracy: 0.6380\n",
      "Epoch 23/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0308 - accuracy: 0.6888 - val_loss: 1.0567 - val_accuracy: 0.6590\n",
      "Epoch 24/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9980 - accuracy: 0.7017 - val_loss: 1.0298 - val_accuracy: 0.6670\n",
      "Epoch 25/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9674 - accuracy: 0.7088 - val_loss: 1.0016 - val_accuracy: 0.6680\n",
      "Epoch 26/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9387 - accuracy: 0.7133 - val_loss: 0.9750 - val_accuracy: 0.6800\n",
      "Epoch 27/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9129 - accuracy: 0.7223 - val_loss: 0.9513 - val_accuracy: 0.6760\n",
      "Epoch 28/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8877 - accuracy: 0.7261 - val_loss: 0.9320 - val_accuracy: 0.6770\n",
      "Epoch 29/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8649 - accuracy: 0.7288 - val_loss: 0.9107 - val_accuracy: 0.6840\n",
      "Epoch 30/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8432 - accuracy: 0.7345 - val_loss: 0.8954 - val_accuracy: 0.6930\n",
      "Epoch 31/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8230 - accuracy: 0.7419 - val_loss: 0.8777 - val_accuracy: 0.6910\n",
      "Epoch 32/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8043 - accuracy: 0.7448 - val_loss: 0.8594 - val_accuracy: 0.6960\n",
      "Epoch 33/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7865 - accuracy: 0.7473 - val_loss: 0.8454 - val_accuracy: 0.7010\n",
      "Epoch 34/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7707 - accuracy: 0.7529 - val_loss: 0.8302 - val_accuracy: 0.7080\n",
      "Epoch 35/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7556 - accuracy: 0.7564 - val_loss: 0.8179 - val_accuracy: 0.7080\n",
      "Epoch 36/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.7583 - val_loss: 0.8117 - val_accuracy: 0.7030\n",
      "Epoch 37/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7277 - accuracy: 0.7613 - val_loss: 0.7993 - val_accuracy: 0.7090\n",
      "Epoch 38/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7147 - accuracy: 0.7653 - val_loss: 0.7946 - val_accuracy: 0.7110\n",
      "Epoch 39/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.7695 - val_loss: 0.7776 - val_accuracy: 0.7160\n",
      "Epoch 40/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.7715 - val_loss: 0.7727 - val_accuracy: 0.7100\n",
      "Epoch 41/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.7753 - val_loss: 0.7604 - val_accuracy: 0.7180\n",
      "Epoch 42/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.7775 - val_loss: 0.7536 - val_accuracy: 0.7170\n",
      "Epoch 43/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7792 - val_loss: 0.7483 - val_accuracy: 0.7180\n",
      "Epoch 44/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7820 - val_loss: 0.7433 - val_accuracy: 0.7210\n",
      "Epoch 45/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7849 - val_loss: 0.7380 - val_accuracy: 0.7230\n",
      "Epoch 46/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7875 - val_loss: 0.7337 - val_accuracy: 0.7300\n",
      "Epoch 47/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7881 - val_loss: 0.7251 - val_accuracy: 0.7290\n",
      "Epoch 48/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.7933 - val_loss: 0.7229 - val_accuracy: 0.7220\n",
      "Epoch 49/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7923 - val_loss: 0.7149 - val_accuracy: 0.7290\n",
      "Epoch 50/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7951 - val_loss: 0.7126 - val_accuracy: 0.7350\n",
      "Epoch 51/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.7969 - val_loss: 0.7107 - val_accuracy: 0.7280\n",
      "Epoch 52/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.7988 - val_loss: 0.7048 - val_accuracy: 0.7310\n",
      "Epoch 53/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.8015 - val_loss: 0.6999 - val_accuracy: 0.7340\n",
      "Epoch 54/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.8029 - val_loss: 0.6989 - val_accuracy: 0.7320\n",
      "Epoch 55/60\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.8031 - val_loss: 0.6943 - val_accuracy: 0.7390\n",
      "Epoch 56/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.8060 - val_loss: 0.6939 - val_accuracy: 0.7320\n",
      "Epoch 57/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.8079 - val_loss: 0.6946 - val_accuracy: 0.7360\n",
      "Epoch 58/60\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.8099 - val_loss: 0.6901 - val_accuracy: 0.7380\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.8128 - val_loss: 0.6881 - val_accuracy: 0.7400\n",
      "Epoch 60/60\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8165 - val_loss: 0.6814 - val_accuracy: 0.7360\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_shape = (2000, ))) \n",
    "model.add(Dense(25, activation = 'relu'))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_val = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we did before, get our results using `model.evaluate()` on the appropriate variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 485us/step - loss: 0.5404 - accuracy: 0.8143\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 510us/step - loss: 0.6634 - accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5404193997383118, 0.8142666816711426]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train  # Expected Output: [0.58606486314137773, 0.79826666669845581]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.663418710231781, 0.7379999756813049]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test # [0.74768974288304646, 0.71333333365122475]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! Our test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs one we fitted before.\n",
    "\n",
    "Now, let's see what else we can do to improve the result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include L2 regularization. You can easily do this in keras adding the argument `kernel_regulizers.l2` and adding a value for the regularization parameter lambda between parentheses.\n",
    "\n",
    "In the cell below: \n",
    "\n",
    "* Recreate the same model we did before.\n",
    "* In our two hidden layers (but not our output layer), add in the parameter `kernel_regularizer=regularizers.l2(0.005)` to add L2 regularization to each hidden layer.  \n",
    "* Compile the model with the same hyperparameters as we did before. \n",
    "* Fit the model with the same hyperparameters as we did before, but this time for `120` epochs.\n",
    "* Store the fitted model that the `.fit` call returns inside a variable called `L2_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.6063 - accuracy: 0.1544 - val_loss: 2.5878 - val_accuracy: 0.1620\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.5801 - accuracy: 0.1748 - val_loss: 2.5661 - val_accuracy: 0.1850\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.5587 - accuracy: 0.1935 - val_loss: 2.5453 - val_accuracy: 0.2090\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.5364 - accuracy: 0.2165 - val_loss: 2.5217 - val_accuracy: 0.2210\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.5109 - accuracy: 0.2440 - val_loss: 2.4956 - val_accuracy: 0.2560\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.4820 - accuracy: 0.2705 - val_loss: 2.4657 - val_accuracy: 0.2840\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4493 - accuracy: 0.3012 - val_loss: 2.4320 - val_accuracy: 0.3090\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4124 - accuracy: 0.3365 - val_loss: 2.3928 - val_accuracy: 0.3590\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3703 - accuracy: 0.3713 - val_loss: 2.3484 - val_accuracy: 0.3990\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3230 - accuracy: 0.4052 - val_loss: 2.3000 - val_accuracy: 0.4290\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2721 - accuracy: 0.4393 - val_loss: 2.2482 - val_accuracy: 0.4490\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2194 - accuracy: 0.4659 - val_loss: 2.1962 - val_accuracy: 0.4620\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1659 - accuracy: 0.4869 - val_loss: 2.1454 - val_accuracy: 0.5010\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1133 - accuracy: 0.5208 - val_loss: 2.0936 - val_accuracy: 0.5200\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0614 - accuracy: 0.5389 - val_loss: 2.0448 - val_accuracy: 0.5440\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0108 - accuracy: 0.5608 - val_loss: 1.9978 - val_accuracy: 0.5610\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9623 - accuracy: 0.5820 - val_loss: 1.9517 - val_accuracy: 0.5760\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9152 - accuracy: 0.6007 - val_loss: 1.9067 - val_accuracy: 0.5930\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8699 - accuracy: 0.6141 - val_loss: 1.8658 - val_accuracy: 0.6170\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8262 - accuracy: 0.6304 - val_loss: 1.8246 - val_accuracy: 0.6240\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7841 - accuracy: 0.6408 - val_loss: 1.7863 - val_accuracy: 0.6350\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7443 - accuracy: 0.6539 - val_loss: 1.7481 - val_accuracy: 0.6510\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7063 - accuracy: 0.6696 - val_loss: 1.7140 - val_accuracy: 0.6560\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6707 - accuracy: 0.6741 - val_loss: 1.6818 - val_accuracy: 0.6730\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6358 - accuracy: 0.6852 - val_loss: 1.6507 - val_accuracy: 0.6780\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6039 - accuracy: 0.6945 - val_loss: 1.6208 - val_accuracy: 0.6840\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5731 - accuracy: 0.7031 - val_loss: 1.5949 - val_accuracy: 0.6880\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5444 - accuracy: 0.7099 - val_loss: 1.5734 - val_accuracy: 0.6850\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5174 - accuracy: 0.7116 - val_loss: 1.5464 - val_accuracy: 0.6880\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4919 - accuracy: 0.7227 - val_loss: 1.5244 - val_accuracy: 0.6930\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4681 - accuracy: 0.7231 - val_loss: 1.5087 - val_accuracy: 0.6930\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4460 - accuracy: 0.7275 - val_loss: 1.4871 - val_accuracy: 0.7050\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4250 - accuracy: 0.7291 - val_loss: 1.4662 - val_accuracy: 0.7020\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4053 - accuracy: 0.7368 - val_loss: 1.4511 - val_accuracy: 0.6990\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3867 - accuracy: 0.7420 - val_loss: 1.4328 - val_accuracy: 0.7090\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3695 - accuracy: 0.7437 - val_loss: 1.4205 - val_accuracy: 0.7100\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3531 - accuracy: 0.7469 - val_loss: 1.4047 - val_accuracy: 0.7110\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3378 - accuracy: 0.7507 - val_loss: 1.3920 - val_accuracy: 0.7180\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3230 - accuracy: 0.7536 - val_loss: 1.3843 - val_accuracy: 0.7050\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3092 - accuracy: 0.7553 - val_loss: 1.3705 - val_accuracy: 0.7140\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2959 - accuracy: 0.7577 - val_loss: 1.3645 - val_accuracy: 0.7100\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2834 - accuracy: 0.7623 - val_loss: 1.3507 - val_accuracy: 0.7210\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2713 - accuracy: 0.7677 - val_loss: 1.3426 - val_accuracy: 0.7170\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2600 - accuracy: 0.7676 - val_loss: 1.3369 - val_accuracy: 0.7160\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2494 - accuracy: 0.7692 - val_loss: 1.3240 - val_accuracy: 0.7210\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2387 - accuracy: 0.7709 - val_loss: 1.3182 - val_accuracy: 0.7180\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.7732 - val_loss: 1.3094 - val_accuracy: 0.7230\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2190 - accuracy: 0.7772 - val_loss: 1.3024 - val_accuracy: 0.7250\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2097 - accuracy: 0.7768 - val_loss: 1.2969 - val_accuracy: 0.7210\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2010 - accuracy: 0.7791 - val_loss: 1.2925 - val_accuracy: 0.7250\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.7831 - val_loss: 1.2874 - val_accuracy: 0.7280\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1842 - accuracy: 0.7841 - val_loss: 1.2789 - val_accuracy: 0.7320\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1756 - accuracy: 0.7859 - val_loss: 1.2724 - val_accuracy: 0.7270\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1677 - accuracy: 0.7863 - val_loss: 1.2692 - val_accuracy: 0.7240\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1603 - accuracy: 0.7899 - val_loss: 1.2623 - val_accuracy: 0.7310\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1527 - accuracy: 0.7909 - val_loss: 1.2554 - val_accuracy: 0.7320\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1453 - accuracy: 0.7932 - val_loss: 1.2509 - val_accuracy: 0.7320\n",
      "Epoch 58/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1384 - accuracy: 0.7941 - val_loss: 1.2490 - val_accuracy: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1316 - accuracy: 0.7955 - val_loss: 1.2442 - val_accuracy: 0.7360\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1246 - accuracy: 0.7975 - val_loss: 1.2403 - val_accuracy: 0.7310\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1179 - accuracy: 0.7972 - val_loss: 1.2329 - val_accuracy: 0.7350\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1115 - accuracy: 0.8007 - val_loss: 1.2316 - val_accuracy: 0.7330\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.8017 - val_loss: 1.2303 - val_accuracy: 0.7300\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.8015 - val_loss: 1.2246 - val_accuracy: 0.7350\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0931 - accuracy: 0.8061 - val_loss: 1.2208 - val_accuracy: 0.7280\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0866 - accuracy: 0.8073 - val_loss: 1.2176 - val_accuracy: 0.7360\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0813 - accuracy: 0.8073 - val_loss: 1.2114 - val_accuracy: 0.7390\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0752 - accuracy: 0.8101 - val_loss: 1.2073 - val_accuracy: 0.7390\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0695 - accuracy: 0.8128 - val_loss: 1.2061 - val_accuracy: 0.7350\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0638 - accuracy: 0.8121 - val_loss: 1.2043 - val_accuracy: 0.7380\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0583 - accuracy: 0.8156 - val_loss: 1.1980 - val_accuracy: 0.7400\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0528 - accuracy: 0.8160 - val_loss: 1.1926 - val_accuracy: 0.7380\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0475 - accuracy: 0.8191 - val_loss: 1.1891 - val_accuracy: 0.7390\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0422 - accuracy: 0.8171 - val_loss: 1.1881 - val_accuracy: 0.7380\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0369 - accuracy: 0.8187 - val_loss: 1.1841 - val_accuracy: 0.7410\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0320 - accuracy: 0.8200 - val_loss: 1.1803 - val_accuracy: 0.7420\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.8235 - val_loss: 1.1818 - val_accuracy: 0.7360\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0216 - accuracy: 0.8239 - val_loss: 1.1744 - val_accuracy: 0.7410\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0168 - accuracy: 0.8211 - val_loss: 1.1726 - val_accuracy: 0.7370\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0117 - accuracy: 0.8253 - val_loss: 1.1718 - val_accuracy: 0.7370\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0074 - accuracy: 0.8267 - val_loss: 1.1701 - val_accuracy: 0.7400\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.0024 - accuracy: 0.8256 - val_loss: 1.1648 - val_accuracy: 0.7410\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9976 - accuracy: 0.8287 - val_loss: 1.1610 - val_accuracy: 0.7370\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9929 - accuracy: 0.8311 - val_loss: 1.1652 - val_accuracy: 0.7390\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9886 - accuracy: 0.8313 - val_loss: 1.1568 - val_accuracy: 0.7400\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9837 - accuracy: 0.8352 - val_loss: 1.1548 - val_accuracy: 0.7430\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9794 - accuracy: 0.8343 - val_loss: 1.1534 - val_accuracy: 0.7380\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9751 - accuracy: 0.8336 - val_loss: 1.1504 - val_accuracy: 0.7440\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9706 - accuracy: 0.8355 - val_loss: 1.1466 - val_accuracy: 0.7440\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9659 - accuracy: 0.8376 - val_loss: 1.1464 - val_accuracy: 0.7450\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9619 - accuracy: 0.8389 - val_loss: 1.1440 - val_accuracy: 0.7400\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9575 - accuracy: 0.8405 - val_loss: 1.1421 - val_accuracy: 0.7460\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9534 - accuracy: 0.8392 - val_loss: 1.1373 - val_accuracy: 0.7480\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9494 - accuracy: 0.8427 - val_loss: 1.1369 - val_accuracy: 0.7450\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9451 - accuracy: 0.8431 - val_loss: 1.1342 - val_accuracy: 0.7470\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9410 - accuracy: 0.8411 - val_loss: 1.1282 - val_accuracy: 0.7460\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9367 - accuracy: 0.8459 - val_loss: 1.1279 - val_accuracy: 0.7440\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9328 - accuracy: 0.8459 - val_loss: 1.1256 - val_accuracy: 0.7540\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9286 - accuracy: 0.8468 - val_loss: 1.1234 - val_accuracy: 0.7460\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9252 - accuracy: 0.8485 - val_loss: 1.1225 - val_accuracy: 0.7500\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9209 - accuracy: 0.8491 - val_loss: 1.1196 - val_accuracy: 0.7480\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9172 - accuracy: 0.8507 - val_loss: 1.1176 - val_accuracy: 0.7510\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.8511 - val_loss: 1.1149 - val_accuracy: 0.7630\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 0.8505 - val_loss: 1.1136 - val_accuracy: 0.7570\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9060 - accuracy: 0.8516 - val_loss: 1.1111 - val_accuracy: 0.7500\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.8544 - val_loss: 1.1137 - val_accuracy: 0.7510\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8985 - accuracy: 0.8555 - val_loss: 1.1131 - val_accuracy: 0.7420\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.8565 - val_loss: 1.1074 - val_accuracy: 0.7440\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.8569 - val_loss: 1.1020 - val_accuracy: 0.7570\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8875 - accuracy: 0.8603 - val_loss: 1.1020 - val_accuracy: 0.7600\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8838 - accuracy: 0.8591 - val_loss: 1.1024 - val_accuracy: 0.7490\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8803 - accuracy: 0.8612 - val_loss: 1.0974 - val_accuracy: 0.7530\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8768 - accuracy: 0.8623 - val_loss: 1.0946 - val_accuracy: 0.7610\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8732 - accuracy: 0.8613 - val_loss: 1.0970 - val_accuracy: 0.7450\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8696 - accuracy: 0.8619 - val_loss: 1.0964 - val_accuracy: 0.7510\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8665 - accuracy: 0.8629 - val_loss: 1.0936 - val_accuracy: 0.7530\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8627 - accuracy: 0.8652 - val_loss: 1.0906 - val_accuracy: 0.7560\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8595 - accuracy: 0.8656 - val_loss: 1.0868 - val_accuracy: 0.7560\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8559 - accuracy: 0.8692 - val_loss: 1.0846 - val_accuracy: 0.7570\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8524 - accuracy: 0.8667 - val_loss: 1.0824 - val_accuracy: 0.7580\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu',input_shape = (2000, ), kernel_regularizer = regularizers.l2(0.005))) \n",
    "model.add(Dense(25, activation = 'relu', kernel_regularizer = regularizers.l2(0.005)))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "l2_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how regularization has affected our model results.  \n",
    "\n",
    "Run the cell below to get the model's `.history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = l2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs).\n",
    "\n",
    "Run the cell below to visualize our training and validation accuracy both with and without L2 regularization, so that we can compare them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc_values = L2_model_dict['accuracy'] \n",
    "val_acc_values = L2_model_dict['val_accuracy']\n",
    "model_acc = model_val_dict['accuracy']\n",
    "model_val_acc = model_val_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc L2')\n",
    "plt.plot(epochs, val_acc_values, 'g', label='Validation acc L2')\n",
    "plt.plot(epochs, model_acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, model_val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training & validation accuracy L2 vs regular')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. We notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at L1 regularization. Will this work better?\n",
    "\n",
    "In the cell below: \n",
    "\n",
    "* Recreate the same model we did above, but this time, set the `kernel_regularizer` to `regularizers.l1(0.005)` inside both hidden layers. \n",
    "* Compile and fit the model exactly as we did for our L2 Regularization experiment (`120` epochs) \n",
    "* Store the fitted model that the `.fit` call returns inside a variable called `L1_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 15.9840 - accuracy: 0.1715 - val_loss: 15.5720 - val_accuracy: 0.2090\n",
      "Epoch 2/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 15.2214 - accuracy: 0.1995 - val_loss: 14.8262 - val_accuracy: 0.2200\n",
      "Epoch 3/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 14.4852 - accuracy: 0.2048 - val_loss: 14.1043 - val_accuracy: 0.2290\n",
      "Epoch 4/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 13.7713 - accuracy: 0.2107 - val_loss: 13.4033 - val_accuracy: 0.2290\n",
      "Epoch 5/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 13.0777 - accuracy: 0.2193 - val_loss: 12.7223 - val_accuracy: 0.2440\n",
      "Epoch 6/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 12.4040 - accuracy: 0.2391 - val_loss: 12.0599 - val_accuracy: 0.2520\n",
      "Epoch 7/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.7492 - accuracy: 0.2604 - val_loss: 11.4158 - val_accuracy: 0.2810\n",
      "Epoch 8/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.1128 - accuracy: 0.2977 - val_loss: 10.7912 - val_accuracy: 0.3180\n",
      "Epoch 9/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 10.4958 - accuracy: 0.3319 - val_loss: 10.1865 - val_accuracy: 0.3470\n",
      "Epoch 10/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 9.8992 - accuracy: 0.3597 - val_loss: 9.6050 - val_accuracy: 0.3840\n",
      "Epoch 11/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 9.3233 - accuracy: 0.3944 - val_loss: 9.0395 - val_accuracy: 0.3950\n",
      "Epoch 12/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 8.7693 - accuracy: 0.4084 - val_loss: 8.4982 - val_accuracy: 0.4230\n",
      "Epoch 13/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 8.2373 - accuracy: 0.4353 - val_loss: 7.9785 - val_accuracy: 0.4480\n",
      "Epoch 14/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.7271 - accuracy: 0.4636 - val_loss: 7.4798 - val_accuracy: 0.4690\n",
      "Epoch 15/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.2379 - accuracy: 0.4864 - val_loss: 7.0040 - val_accuracy: 0.5000\n",
      "Epoch 16/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 6.7719 - accuracy: 0.5124 - val_loss: 6.5497 - val_accuracy: 0.5080\n",
      "Epoch 17/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 6.3289 - accuracy: 0.5217 - val_loss: 6.1203 - val_accuracy: 0.5110\n",
      "Epoch 18/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.9094 - accuracy: 0.5353 - val_loss: 5.7125 - val_accuracy: 0.5230\n",
      "Epoch 19/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 5.5123 - accuracy: 0.5504 - val_loss: 5.3294 - val_accuracy: 0.5380\n",
      "Epoch 20/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.1389 - accuracy: 0.5607 - val_loss: 4.9672 - val_accuracy: 0.5540\n",
      "Epoch 21/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.7881 - accuracy: 0.5713 - val_loss: 4.6279 - val_accuracy: 0.5580\n",
      "Epoch 22/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.4601 - accuracy: 0.5779 - val_loss: 4.3134 - val_accuracy: 0.5660\n",
      "Epoch 23/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 4.1546 - accuracy: 0.5875 - val_loss: 4.0189 - val_accuracy: 0.5790\n",
      "Epoch 24/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 3.8711 - accuracy: 0.5896 - val_loss: 3.7468 - val_accuracy: 0.5900\n",
      "Epoch 25/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 3.6101 - accuracy: 0.5980 - val_loss: 3.4993 - val_accuracy: 0.5760\n",
      "Epoch 26/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 3.3709 - accuracy: 0.6021 - val_loss: 3.2694 - val_accuracy: 0.6100\n",
      "Epoch 27/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 3.1537 - accuracy: 0.6064 - val_loss: 3.0632 - val_accuracy: 0.6110\n",
      "Epoch 28/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.9583 - accuracy: 0.6092 - val_loss: 2.8801 - val_accuracy: 0.6120\n",
      "Epoch 29/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.7837 - accuracy: 0.6136 - val_loss: 2.7143 - val_accuracy: 0.6210\n",
      "Epoch 30/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.6300 - accuracy: 0.6176 - val_loss: 2.5730 - val_accuracy: 0.6220\n",
      "Epoch 31/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.4971 - accuracy: 0.6196 - val_loss: 2.4518 - val_accuracy: 0.6230\n",
      "Epoch 32/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3842 - accuracy: 0.6264 - val_loss: 2.3460 - val_accuracy: 0.6230\n",
      "Epoch 33/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2898 - accuracy: 0.6260 - val_loss: 2.2613 - val_accuracy: 0.6250\n",
      "Epoch 34/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.2142 - accuracy: 0.6287 - val_loss: 2.1959 - val_accuracy: 0.6370\n",
      "Epoch 35/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1553 - accuracy: 0.6324 - val_loss: 2.1454 - val_accuracy: 0.6240\n",
      "Epoch 36/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.1109 - accuracy: 0.6336 - val_loss: 2.1074 - val_accuracy: 0.6320\n",
      "Epoch 37/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0776 - accuracy: 0.6347 - val_loss: 2.0772 - val_accuracy: 0.6360\n",
      "Epoch 38/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0510 - accuracy: 0.6377 - val_loss: 2.0528 - val_accuracy: 0.6350\n",
      "Epoch 39/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0276 - accuracy: 0.6373 - val_loss: 2.0306 - val_accuracy: 0.6350\n",
      "Epoch 40/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.0071 - accuracy: 0.6416 - val_loss: 2.0113 - val_accuracy: 0.6410\n",
      "Epoch 41/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.9880 - accuracy: 0.6475 - val_loss: 1.9971 - val_accuracy: 0.6430\n",
      "Epoch 42/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9699 - accuracy: 0.6483 - val_loss: 1.9771 - val_accuracy: 0.6400\n",
      "Epoch 43/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9528 - accuracy: 0.6503 - val_loss: 1.9645 - val_accuracy: 0.6420\n",
      "Epoch 44/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9371 - accuracy: 0.6529 - val_loss: 1.9462 - val_accuracy: 0.6460\n",
      "Epoch 45/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9214 - accuracy: 0.6559 - val_loss: 1.9314 - val_accuracy: 0.6480\n",
      "Epoch 46/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.9073 - accuracy: 0.6580 - val_loss: 1.9185 - val_accuracy: 0.6420\n",
      "Epoch 47/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8927 - accuracy: 0.6584 - val_loss: 1.9035 - val_accuracy: 0.6510\n",
      "Epoch 48/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8786 - accuracy: 0.6641 - val_loss: 1.8899 - val_accuracy: 0.6490\n",
      "Epoch 49/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8658 - accuracy: 0.6644 - val_loss: 1.8767 - val_accuracy: 0.6520\n",
      "Epoch 50/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8528 - accuracy: 0.6632 - val_loss: 1.8691 - val_accuracy: 0.6530\n",
      "Epoch 51/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8402 - accuracy: 0.6668 - val_loss: 1.8564 - val_accuracy: 0.6540\n",
      "Epoch 52/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8287 - accuracy: 0.6680 - val_loss: 1.8420 - val_accuracy: 0.6610\n",
      "Epoch 53/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8163 - accuracy: 0.6692 - val_loss: 1.8294 - val_accuracy: 0.6610\n",
      "Epoch 54/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8049 - accuracy: 0.6696 - val_loss: 1.8181 - val_accuracy: 0.6580\n",
      "Epoch 55/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7937 - accuracy: 0.6723 - val_loss: 1.8141 - val_accuracy: 0.6620\n",
      "Epoch 56/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7833 - accuracy: 0.6733 - val_loss: 1.8011 - val_accuracy: 0.6670\n",
      "Epoch 57/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7728 - accuracy: 0.6751 - val_loss: 1.7878 - val_accuracy: 0.6670\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7619 - accuracy: 0.6771 - val_loss: 1.7815 - val_accuracy: 0.6690\n",
      "Epoch 59/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7518 - accuracy: 0.6771 - val_loss: 1.7732 - val_accuracy: 0.6690\n",
      "Epoch 60/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7420 - accuracy: 0.6787 - val_loss: 1.7575 - val_accuracy: 0.6670\n",
      "Epoch 61/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7322 - accuracy: 0.6815 - val_loss: 1.7490 - val_accuracy: 0.6660\n",
      "Epoch 62/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7225 - accuracy: 0.6796 - val_loss: 1.7417 - val_accuracy: 0.6710\n",
      "Epoch 63/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7130 - accuracy: 0.6812 - val_loss: 1.7354 - val_accuracy: 0.6770\n",
      "Epoch 64/120\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7042 - accuracy: 0.6815 - val_loss: 1.7210 - val_accuracy: 0.6690\n",
      "Epoch 65/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6944 - accuracy: 0.6839 - val_loss: 1.7182 - val_accuracy: 0.6750\n",
      "Epoch 66/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6856 - accuracy: 0.6856 - val_loss: 1.7038 - val_accuracy: 0.6770\n",
      "Epoch 67/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6770 - accuracy: 0.6851 - val_loss: 1.6986 - val_accuracy: 0.6740\n",
      "Epoch 68/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6687 - accuracy: 0.6881 - val_loss: 1.6866 - val_accuracy: 0.6770\n",
      "Epoch 69/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6600 - accuracy: 0.6873 - val_loss: 1.6780 - val_accuracy: 0.6760\n",
      "Epoch 70/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6514 - accuracy: 0.6885 - val_loss: 1.6716 - val_accuracy: 0.6780\n",
      "Epoch 71/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6433 - accuracy: 0.6893 - val_loss: 1.6747 - val_accuracy: 0.6800\n",
      "Epoch 72/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6357 - accuracy: 0.6917 - val_loss: 1.6566 - val_accuracy: 0.6760\n",
      "Epoch 73/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6269 - accuracy: 0.6927 - val_loss: 1.6474 - val_accuracy: 0.6740\n",
      "Epoch 74/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6192 - accuracy: 0.6921 - val_loss: 1.6391 - val_accuracy: 0.6770\n",
      "Epoch 75/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6114 - accuracy: 0.6917 - val_loss: 1.6356 - val_accuracy: 0.6740\n",
      "Epoch 76/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6038 - accuracy: 0.6939 - val_loss: 1.6257 - val_accuracy: 0.6770\n",
      "Epoch 77/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5965 - accuracy: 0.6951 - val_loss: 1.6195 - val_accuracy: 0.6790\n",
      "Epoch 78/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5886 - accuracy: 0.6964 - val_loss: 1.6169 - val_accuracy: 0.6780\n",
      "Epoch 79/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5813 - accuracy: 0.6960 - val_loss: 1.6075 - val_accuracy: 0.6830\n",
      "Epoch 80/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5736 - accuracy: 0.6959 - val_loss: 1.5960 - val_accuracy: 0.6800\n",
      "Epoch 81/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5664 - accuracy: 0.6971 - val_loss: 1.5889 - val_accuracy: 0.6760\n",
      "Epoch 82/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5591 - accuracy: 0.6977 - val_loss: 1.5828 - val_accuracy: 0.6790\n",
      "Epoch 83/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5523 - accuracy: 0.6988 - val_loss: 1.5754 - val_accuracy: 0.6800\n",
      "Epoch 84/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5450 - accuracy: 0.6983 - val_loss: 1.5705 - val_accuracy: 0.6810\n",
      "Epoch 85/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5382 - accuracy: 0.7009 - val_loss: 1.5622 - val_accuracy: 0.6780\n",
      "Epoch 86/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5311 - accuracy: 0.6991 - val_loss: 1.5564 - val_accuracy: 0.6830\n",
      "Epoch 87/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5242 - accuracy: 0.7001 - val_loss: 1.5492 - val_accuracy: 0.6850\n",
      "Epoch 88/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5182 - accuracy: 0.6995 - val_loss: 1.5457 - val_accuracy: 0.6860\n",
      "Epoch 89/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5113 - accuracy: 0.7001 - val_loss: 1.5356 - val_accuracy: 0.6860\n",
      "Epoch 90/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.5044 - accuracy: 0.7003 - val_loss: 1.5299 - val_accuracy: 0.6850\n",
      "Epoch 91/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4991 - accuracy: 0.7011 - val_loss: 1.5300 - val_accuracy: 0.6850\n",
      "Epoch 92/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4918 - accuracy: 0.7052 - val_loss: 1.5269 - val_accuracy: 0.6820\n",
      "Epoch 93/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4861 - accuracy: 0.7041 - val_loss: 1.5196 - val_accuracy: 0.6860\n",
      "Epoch 94/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4795 - accuracy: 0.7035 - val_loss: 1.5102 - val_accuracy: 0.6820\n",
      "Epoch 95/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4736 - accuracy: 0.7036 - val_loss: 1.5000 - val_accuracy: 0.6880\n",
      "Epoch 96/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4673 - accuracy: 0.7055 - val_loss: 1.4938 - val_accuracy: 0.6830\n",
      "Epoch 97/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4611 - accuracy: 0.7067 - val_loss: 1.4847 - val_accuracy: 0.6900\n",
      "Epoch 98/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4550 - accuracy: 0.7045 - val_loss: 1.4803 - val_accuracy: 0.6870\n",
      "Epoch 99/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4491 - accuracy: 0.7067 - val_loss: 1.4819 - val_accuracy: 0.6850\n",
      "Epoch 100/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4430 - accuracy: 0.7075 - val_loss: 1.4697 - val_accuracy: 0.6850\n",
      "Epoch 101/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4374 - accuracy: 0.7079 - val_loss: 1.4619 - val_accuracy: 0.6930\n",
      "Epoch 102/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4317 - accuracy: 0.7075 - val_loss: 1.4570 - val_accuracy: 0.6940\n",
      "Epoch 103/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4257 - accuracy: 0.7093 - val_loss: 1.4523 - val_accuracy: 0.6900\n",
      "Epoch 104/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4207 - accuracy: 0.7089 - val_loss: 1.4488 - val_accuracy: 0.6920\n",
      "Epoch 105/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4146 - accuracy: 0.7087 - val_loss: 1.4443 - val_accuracy: 0.6930\n",
      "Epoch 106/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4092 - accuracy: 0.7108 - val_loss: 1.4450 - val_accuracy: 0.6930\n",
      "Epoch 107/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4040 - accuracy: 0.7119 - val_loss: 1.4304 - val_accuracy: 0.6990\n",
      "Epoch 108/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3986 - accuracy: 0.7135 - val_loss: 1.4241 - val_accuracy: 0.6970\n",
      "Epoch 109/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.7139 - val_loss: 1.4197 - val_accuracy: 0.6960\n",
      "Epoch 110/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3874 - accuracy: 0.7136 - val_loss: 1.4162 - val_accuracy: 0.6940\n",
      "Epoch 111/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3825 - accuracy: 0.7137 - val_loss: 1.4112 - val_accuracy: 0.6950\n",
      "Epoch 112/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3773 - accuracy: 0.7137 - val_loss: 1.4064 - val_accuracy: 0.6960\n",
      "Epoch 113/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3723 - accuracy: 0.7129 - val_loss: 1.3999 - val_accuracy: 0.6960\n",
      "Epoch 114/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3671 - accuracy: 0.7149 - val_loss: 1.3948 - val_accuracy: 0.6980\n",
      "Epoch 115/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3614 - accuracy: 0.7149 - val_loss: 1.3914 - val_accuracy: 0.6990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3565 - accuracy: 0.7133 - val_loss: 1.3845 - val_accuracy: 0.6970\n",
      "Epoch 117/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3517 - accuracy: 0.7149 - val_loss: 1.3857 - val_accuracy: 0.7000\n",
      "Epoch 118/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3467 - accuracy: 0.7152 - val_loss: 1.3752 - val_accuracy: 0.6980\n",
      "Epoch 119/120\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3418 - accuracy: 0.7173 - val_loss: 1.3719 - val_accuracy: 0.7010\n",
      "Epoch 120/120\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3368 - accuracy: 0.7159 - val_loss: 1.3645 - val_accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu',input_shape = (2000, ), kernel_regularizer = regularizers.l1(0.005))) \n",
    "model.add(Dense(25, activation = 'relu', kernel_regularizer = regularizers.l1(0.005)))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "l1_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to get and visualize the model's `.history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l1_model_dict = l1_model.history\n",
    "plt.clf()\n",
    "\n",
    "acc_values = l1_model_dict['accuracy'] \n",
    "val_acc_values = l1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc L1')\n",
    "plt.plot(epochs, val_acc_values, 'g.', label='Validation acc L1')\n",
    "plt.title('Training & validation accuracy with L1 regularization')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how The training and validation accuracy don't diverge as much as before! Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like we can still improve the model by training much longer.\n",
    "\n",
    "To complete our comparison, let's use `model.evaluate()` again on the appropriate variables to compare results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 545us/step - loss: 1.3351 - accuracy: 0.7167\n",
      "47/47 [==============================] - 0s 532us/step - loss: 1.3569 - accuracy: 0.6980\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)\n",
    "\n",
    "results_test = model.evaluate(test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3350669145584106, 0.7166666388511658]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train # Expected Output: [1.3186310468037923, 0.72266666663487755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3568840026855469, 0.6980000138282776]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test # Expected Output: [1.3541648308436076, 0.70800000031789145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best we've seen so far, but we were training for quite a while! Let's see if dropout regularization can do even better and/or be more efficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dropout Regularization\n",
    "\n",
    "Dropout Regularization is accomplished by adding in an additional `Dropout` layer wherever we want to use it, and providing a percentage value for how likely any given neuron is to get \"dropped out\" during this layer. \n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Import `Dropout` from `keras.layers`\n",
    "* Recreate the same network we have above, but this time without any L1 or L2 regularization\n",
    "* Add a `Dropout` layer between hidden layer 1 and hidden layer 2.  This should have a dropout chance of `0.3`.\n",
    "* Add a `Dropout` layer between hidden layer 2 and the output layer.  This should have a dropout chance of `0.3`.\n",
    "* Compile the model with the exact same hyperparameters as all other models we've built. \n",
    "* Fit the model with the same hyperparameters we've used above.  But this time, train the model for `200` epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.9910 - accuracy: 0.1175 - val_loss: 1.9569 - val_accuracy: 0.1450\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9579 - accuracy: 0.1437 - val_loss: 1.9410 - val_accuracy: 0.1650\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9435 - accuracy: 0.1595 - val_loss: 1.9307 - val_accuracy: 0.1870\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9334 - accuracy: 0.1848 - val_loss: 1.9226 - val_accuracy: 0.2230\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9233 - accuracy: 0.1923 - val_loss: 1.9143 - val_accuracy: 0.2450\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9155 - accuracy: 0.2033 - val_loss: 1.9049 - val_accuracy: 0.2570\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.9058 - accuracy: 0.2188 - val_loss: 1.8947 - val_accuracy: 0.2670\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8982 - accuracy: 0.2279 - val_loss: 1.8838 - val_accuracy: 0.2810\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8896 - accuracy: 0.2297 - val_loss: 1.8721 - val_accuracy: 0.2900\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8796 - accuracy: 0.2455 - val_loss: 1.8606 - val_accuracy: 0.3060\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8683 - accuracy: 0.2519 - val_loss: 1.8466 - val_accuracy: 0.3160\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8609 - accuracy: 0.2576 - val_loss: 1.8328 - val_accuracy: 0.3400\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8444 - accuracy: 0.2719 - val_loss: 1.8158 - val_accuracy: 0.3450\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8305 - accuracy: 0.2765 - val_loss: 1.7970 - val_accuracy: 0.3620\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.8112 - accuracy: 0.2891 - val_loss: 1.7761 - val_accuracy: 0.3800\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7997 - accuracy: 0.2891 - val_loss: 1.7557 - val_accuracy: 0.3860\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7773 - accuracy: 0.3071 - val_loss: 1.7317 - val_accuracy: 0.4050\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7587 - accuracy: 0.3169 - val_loss: 1.7072 - val_accuracy: 0.4180\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7430 - accuracy: 0.3221 - val_loss: 1.6834 - val_accuracy: 0.4430\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7199 - accuracy: 0.3368 - val_loss: 1.6563 - val_accuracy: 0.4590\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6948 - accuracy: 0.3491 - val_loss: 1.6288 - val_accuracy: 0.4690\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6730 - accuracy: 0.3604 - val_loss: 1.6026 - val_accuracy: 0.4770\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6513 - accuracy: 0.3667 - val_loss: 1.5746 - val_accuracy: 0.4910\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6319 - accuracy: 0.3771 - val_loss: 1.5466 - val_accuracy: 0.5020\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6089 - accuracy: 0.3908 - val_loss: 1.5199 - val_accuracy: 0.5130\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5891 - accuracy: 0.3925 - val_loss: 1.4957 - val_accuracy: 0.5220\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5752 - accuracy: 0.3984 - val_loss: 1.4702 - val_accuracy: 0.5310\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5437 - accuracy: 0.4116 - val_loss: 1.4422 - val_accuracy: 0.5340\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5231 - accuracy: 0.4223 - val_loss: 1.4178 - val_accuracy: 0.5460\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5066 - accuracy: 0.4233 - val_loss: 1.3932 - val_accuracy: 0.5520\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4920 - accuracy: 0.4312 - val_loss: 1.3710 - val_accuracy: 0.5610\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4638 - accuracy: 0.4425 - val_loss: 1.3458 - val_accuracy: 0.5710\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4462 - accuracy: 0.4583 - val_loss: 1.3230 - val_accuracy: 0.5730\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4416 - accuracy: 0.4543 - val_loss: 1.3053 - val_accuracy: 0.5910\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4202 - accuracy: 0.4572 - val_loss: 1.2844 - val_accuracy: 0.6020\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3927 - accuracy: 0.4727 - val_loss: 1.2615 - val_accuracy: 0.5990\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3812 - accuracy: 0.4736 - val_loss: 1.2439 - val_accuracy: 0.6190\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3588 - accuracy: 0.4881 - val_loss: 1.2238 - val_accuracy: 0.6230\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3501 - accuracy: 0.4865 - val_loss: 1.2062 - val_accuracy: 0.6300\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3286 - accuracy: 0.4932 - val_loss: 1.1873 - val_accuracy: 0.6330\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3235 - accuracy: 0.4927 - val_loss: 1.1701 - val_accuracy: 0.6340\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3014 - accuracy: 0.5032 - val_loss: 1.1561 - val_accuracy: 0.6340\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2911 - accuracy: 0.5067 - val_loss: 1.1408 - val_accuracy: 0.6480\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2762 - accuracy: 0.5145 - val_loss: 1.1237 - val_accuracy: 0.6520\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2590 - accuracy: 0.5235 - val_loss: 1.1108 - val_accuracy: 0.6530\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2566 - accuracy: 0.5189 - val_loss: 1.0969 - val_accuracy: 0.6590\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2442 - accuracy: 0.5320 - val_loss: 1.0824 - val_accuracy: 0.6640\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2195 - accuracy: 0.5429 - val_loss: 1.0665 - val_accuracy: 0.6620\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2123 - accuracy: 0.5429 - val_loss: 1.0527 - val_accuracy: 0.6670\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1871 - accuracy: 0.5520 - val_loss: 1.0397 - val_accuracy: 0.6720\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1881 - accuracy: 0.5507 - val_loss: 1.0273 - val_accuracy: 0.6790\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.1806 - accuracy: 0.5509 - val_loss: 1.0156 - val_accuracy: 0.6800\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1698 - accuracy: 0.5596 - val_loss: 1.0054 - val_accuracy: 0.6780\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.1657 - accuracy: 0.5644 - val_loss: 0.9954 - val_accuracy: 0.6830\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.1413 - accuracy: 0.5711 - val_loss: 0.9842 - val_accuracy: 0.6870\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1324 - accuracy: 0.5669 - val_loss: 0.9732 - val_accuracy: 0.6840\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.1267 - accuracy: 0.5776 - val_loss: 0.9657 - val_accuracy: 0.6850\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1109 - accuracy: 0.5840 - val_loss: 0.9536 - val_accuracy: 0.6920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.1031 - accuracy: 0.5749 - val_loss: 0.9420 - val_accuracy: 0.6900\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0908 - accuracy: 0.5847 - val_loss: 0.9338 - val_accuracy: 0.6950\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0865 - accuracy: 0.5908 - val_loss: 0.9248 - val_accuracy: 0.6930\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0810 - accuracy: 0.5897 - val_loss: 0.9160 - val_accuracy: 0.6960\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0657 - accuracy: 0.5949 - val_loss: 0.9084 - val_accuracy: 0.6950\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0556 - accuracy: 0.5956 - val_loss: 0.8990 - val_accuracy: 0.6990\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0518 - accuracy: 0.5984 - val_loss: 0.8915 - val_accuracy: 0.7030\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0453 - accuracy: 0.6040 - val_loss: 0.8843 - val_accuracy: 0.7060\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0341 - accuracy: 0.6063 - val_loss: 0.8764 - val_accuracy: 0.7010\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0301 - accuracy: 0.6120 - val_loss: 0.8693 - val_accuracy: 0.7040\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0288 - accuracy: 0.6105 - val_loss: 0.8637 - val_accuracy: 0.7100\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0076 - accuracy: 0.6239 - val_loss: 0.8561 - val_accuracy: 0.7110\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0013 - accuracy: 0.6153 - val_loss: 0.8500 - val_accuracy: 0.7070\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.0005 - accuracy: 0.6237 - val_loss: 0.8428 - val_accuracy: 0.7080\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9863 - accuracy: 0.6324 - val_loss: 0.8360 - val_accuracy: 0.7100\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9710 - accuracy: 0.6299 - val_loss: 0.8325 - val_accuracy: 0.7090\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9775 - accuracy: 0.6347 - val_loss: 0.8240 - val_accuracy: 0.7080\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.6423 - val_loss: 0.8192 - val_accuracy: 0.7090\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9651 - accuracy: 0.6361 - val_loss: 0.8132 - val_accuracy: 0.7150\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9540 - accuracy: 0.6445 - val_loss: 0.8077 - val_accuracy: 0.7180\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9457 - accuracy: 0.6431 - val_loss: 0.8033 - val_accuracy: 0.7130\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9537 - accuracy: 0.6421 - val_loss: 0.7995 - val_accuracy: 0.7110\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9334 - accuracy: 0.6519 - val_loss: 0.7944 - val_accuracy: 0.7170\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9361 - accuracy: 0.6527 - val_loss: 0.7892 - val_accuracy: 0.7190\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9224 - accuracy: 0.6500 - val_loss: 0.7841 - val_accuracy: 0.7190\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9084 - accuracy: 0.6571 - val_loss: 0.7778 - val_accuracy: 0.7180\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9128 - accuracy: 0.6557 - val_loss: 0.7743 - val_accuracy: 0.7180\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8995 - accuracy: 0.6627 - val_loss: 0.7693 - val_accuracy: 0.7200\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8905 - accuracy: 0.6652 - val_loss: 0.7672 - val_accuracy: 0.7210\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8878 - accuracy: 0.6656 - val_loss: 0.7626 - val_accuracy: 0.7210\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8847 - accuracy: 0.6596 - val_loss: 0.7593 - val_accuracy: 0.7230\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8889 - accuracy: 0.6629 - val_loss: 0.7562 - val_accuracy: 0.7200\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8859 - accuracy: 0.6688 - val_loss: 0.7536 - val_accuracy: 0.7220\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8630 - accuracy: 0.6764 - val_loss: 0.7508 - val_accuracy: 0.7210\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8615 - accuracy: 0.6825 - val_loss: 0.7461 - val_accuracy: 0.7220\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8616 - accuracy: 0.6728 - val_loss: 0.7438 - val_accuracy: 0.7230\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8640 - accuracy: 0.6721 - val_loss: 0.7403 - val_accuracy: 0.7230\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8627 - accuracy: 0.6812 - val_loss: 0.7394 - val_accuracy: 0.7220\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8415 - accuracy: 0.6841 - val_loss: 0.7359 - val_accuracy: 0.7200\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8491 - accuracy: 0.6791 - val_loss: 0.7301 - val_accuracy: 0.7250\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8337 - accuracy: 0.6905 - val_loss: 0.7288 - val_accuracy: 0.7240\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8356 - accuracy: 0.6860 - val_loss: 0.7247 - val_accuracy: 0.7270\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8236 - accuracy: 0.6932 - val_loss: 0.7217 - val_accuracy: 0.7290\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.6920 - val_loss: 0.7201 - val_accuracy: 0.7290\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8204 - accuracy: 0.6973 - val_loss: 0.7179 - val_accuracy: 0.7280\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.6971 - val_loss: 0.7167 - val_accuracy: 0.7290\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8174 - accuracy: 0.6917 - val_loss: 0.7155 - val_accuracy: 0.7270\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8107 - accuracy: 0.6965 - val_loss: 0.7103 - val_accuracy: 0.7280\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7951 - accuracy: 0.7028 - val_loss: 0.7070 - val_accuracy: 0.7280\n",
      "Epoch 108/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7892 - accuracy: 0.7084 - val_loss: 0.7041 - val_accuracy: 0.7320\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7889 - accuracy: 0.7003 - val_loss: 0.7031 - val_accuracy: 0.7310\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7851 - accuracy: 0.7079 - val_loss: 0.7023 - val_accuracy: 0.7330\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7893 - accuracy: 0.7027 - val_loss: 0.6988 - val_accuracy: 0.7350\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7848 - accuracy: 0.7104 - val_loss: 0.6991 - val_accuracy: 0.7310\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7767 - accuracy: 0.7093 - val_loss: 0.6966 - val_accuracy: 0.7310\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.7160 - val_loss: 0.6960 - val_accuracy: 0.7290\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.7129 - val_loss: 0.6926 - val_accuracy: 0.7350\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.7191 - val_loss: 0.6928 - val_accuracy: 0.7290\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7706 - accuracy: 0.7133 - val_loss: 0.6908 - val_accuracy: 0.7320\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.7129 - val_loss: 0.6874 - val_accuracy: 0.7320\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.7168 - val_loss: 0.6858 - val_accuracy: 0.7350\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7610 - accuracy: 0.7080 - val_loss: 0.6862 - val_accuracy: 0.7310\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.7209 - val_loss: 0.6834 - val_accuracy: 0.7330\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7418 - accuracy: 0.7207 - val_loss: 0.6815 - val_accuracy: 0.7320\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7458 - accuracy: 0.7195 - val_loss: 0.6803 - val_accuracy: 0.7320\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.7092 - val_loss: 0.6802 - val_accuracy: 0.7350\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7255 - accuracy: 0.72 - 0s 4ms/step - loss: 0.7315 - accuracy: 0.7272 - val_loss: 0.6805 - val_accuracy: 0.7330\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.7215 - val_loss: 0.6790 - val_accuracy: 0.7340\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.7317 - val_loss: 0.6738 - val_accuracy: 0.7340\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7415 - accuracy: 0.7233 - val_loss: 0.6730 - val_accuracy: 0.7330\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7103 - accuracy: 0.7411 - val_loss: 0.6747 - val_accuracy: 0.7350\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7213 - accuracy: 0.7300 - val_loss: 0.6731 - val_accuracy: 0.7340\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.7313 - val_loss: 0.6713 - val_accuracy: 0.7330\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.7291 - val_loss: 0.6693 - val_accuracy: 0.7340\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.7325 - val_loss: 0.6670 - val_accuracy: 0.7360\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7110 - accuracy: 0.7331 - val_loss: 0.6671 - val_accuracy: 0.7330\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7086 - accuracy: 0.7329 - val_loss: 0.6640 - val_accuracy: 0.7360\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7051 - accuracy: 0.7375 - val_loss: 0.6644 - val_accuracy: 0.7350\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7030 - accuracy: 0.7372 - val_loss: 0.6636 - val_accuracy: 0.7360\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.7337 - val_loss: 0.6625 - val_accuracy: 0.7400\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.7404 - val_loss: 0.6633 - val_accuracy: 0.7350\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7006 - accuracy: 0.7388 - val_loss: 0.6624 - val_accuracy: 0.7400\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.7397 - val_loss: 0.6608 - val_accuracy: 0.7380\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.7383 - val_loss: 0.6625 - val_accuracy: 0.7380\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.7487 - val_loss: 0.6616 - val_accuracy: 0.7350\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.7459 - val_loss: 0.6593 - val_accuracy: 0.7370\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7451 - val_loss: 0.6575 - val_accuracy: 0.7340\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7504 - val_loss: 0.6561 - val_accuracy: 0.7360\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7419 - val_loss: 0.6590 - val_accuracy: 0.7340\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7561 - val_loss: 0.6539 - val_accuracy: 0.7390\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7497 - val_loss: 0.6549 - val_accuracy: 0.7360\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.7563 - val_loss: 0.6554 - val_accuracy: 0.7390\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7468 - val_loss: 0.6537 - val_accuracy: 0.7360\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7491 - val_loss: 0.6521 - val_accuracy: 0.7370\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.7548 - val_loss: 0.6534 - val_accuracy: 0.7390\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.7541 - val_loss: 0.6499 - val_accuracy: 0.7410\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.7484 - val_loss: 0.6500 - val_accuracy: 0.7390\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.7588 - val_loss: 0.6496 - val_accuracy: 0.7420\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7573 - val_loss: 0.6492 - val_accuracy: 0.7420\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.7525 - val_loss: 0.6515 - val_accuracy: 0.7400\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.7551 - val_loss: 0.6520 - val_accuracy: 0.7370\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.7615 - val_loss: 0.6473 - val_accuracy: 0.7380\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.7612 - val_loss: 0.6463 - val_accuracy: 0.7420\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.7572 - val_loss: 0.6448 - val_accuracy: 0.7430\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7607 - val_loss: 0.6458 - val_accuracy: 0.7390\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.7609 - val_loss: 0.6453 - val_accuracy: 0.7360\n",
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.7593 - val_loss: 0.6437 - val_accuracy: 0.7400\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.7659 - val_loss: 0.6452 - val_accuracy: 0.7380\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.7696 - val_loss: 0.6436 - val_accuracy: 0.7390\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.7605 - val_loss: 0.6438 - val_accuracy: 0.7420\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.7697 - val_loss: 0.6452 - val_accuracy: 0.7370\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7608 - val_loss: 0.6450 - val_accuracy: 0.7360\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7713 - val_loss: 0.6427 - val_accuracy: 0.7410\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.7685 - val_loss: 0.6418 - val_accuracy: 0.7400\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.7724 - val_loss: 0.6426 - val_accuracy: 0.7370\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.7664 - val_loss: 0.6416 - val_accuracy: 0.7380\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.7727 - val_loss: 0.6445 - val_accuracy: 0.7350\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7724 - val_loss: 0.6415 - val_accuracy: 0.7420\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.7704 - val_loss: 0.6384 - val_accuracy: 0.7440\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.7699 - val_loss: 0.6395 - val_accuracy: 0.7430\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7755 - val_loss: 0.6405 - val_accuracy: 0.7390\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7715 - val_loss: 0.6383 - val_accuracy: 0.7460\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.7745 - val_loss: 0.6405 - val_accuracy: 0.7380\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7776 - val_loss: 0.6385 - val_accuracy: 0.7410\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7763 - val_loss: 0.6372 - val_accuracy: 0.7370\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7759 - val_loss: 0.6388 - val_accuracy: 0.7350\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7757 - val_loss: 0.6375 - val_accuracy: 0.7400\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7815 - val_loss: 0.6369 - val_accuracy: 0.7390\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7836 - val_loss: 0.6406 - val_accuracy: 0.7390\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7821 - val_loss: 0.6383 - val_accuracy: 0.7410\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.7764 - val_loss: 0.6375 - val_accuracy: 0.7430\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7809 - val_loss: 0.6373 - val_accuracy: 0.7430\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7851 - val_loss: 0.6385 - val_accuracy: 0.7380\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7805 - val_loss: 0.6354 - val_accuracy: 0.7400\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7865 - val_loss: 0.6363 - val_accuracy: 0.7380\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7849 - val_loss: 0.6358 - val_accuracy: 0.7410\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5765 - accuracy: 0.7833 - val_loss: 0.6362 - val_accuracy: 0.7390\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7867 - val_loss: 0.6368 - val_accuracy: 0.7390\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7857 - val_loss: 0.6341 - val_accuracy: 0.7400\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7875 - val_loss: 0.6363 - val_accuracy: 0.7360\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7821 - val_loss: 0.6350 - val_accuracy: 0.7400\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.79 - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7841 - val_loss: 0.6380 - val_accuracy: 0.7360\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu',input_shape = (2000, ))) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(25, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "l2_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the results from `model.evaluate` to see how this change has affected our training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 476us/step - loss: 0.3919 - accuracy: 0.8571\n",
      "47/47 [==============================] - 0s 510us/step - loss: 0.6049 - accuracy: 0.7607\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)\n",
    "results_test = model.evaluate(test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39189019799232483, 0.8570666909217834]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train # Expected Results: [0.36925017188787462, 0.88026666666666664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.604900062084198, 0.7606666684150696]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test # Expected Results: [0.69210424280166627, 0.74333333365122478]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! However, the variance did become higher again, compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  More Training Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another solution to high variance is to just get more data. We actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple our data set, and see what happens. Note that we are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets.\n",
    "\n",
    "Run the cell below to preprocess our entire dataset, instead of just working with a subset of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "random.seed(123)\n",
    "df = df.sample(40000)\n",
    "df.index = range(40000)\n",
    "product = df[\"Product\"]\n",
    "complaints = df[\"Consumer complaint narrative\"]\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(complaints)\n",
    "sequences = tokenizer.texts_to_sequences(complaints)\n",
    "one_hot_results= tokenizer.texts_to_matrix(complaints, mode='binary')\n",
    "word_index = tokenizer.word_index\n",
    "np.shape(one_hot_results)\n",
    "\n",
    "#one-hot encoding of products\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(product)\n",
    "list(le.classes_)\n",
    "product_cat = le.transform(product) \n",
    "product_onehot = to_categorical(product_cat)\n",
    "\n",
    "# train test split\n",
    "test_index = random.sample(range(1,40000), 4000)\n",
    "test = one_hot_results[test_index]\n",
    "train = np.delete(one_hot_results, test_index, 0)\n",
    "label_test = product_onehot[test_index]\n",
    "label_train = np.delete(product_onehot, test_index, 0)\n",
    "\n",
    "#Validation set\n",
    "random.seed(123)\n",
    "val = train[:3000]\n",
    "train_final = train[3000:]\n",
    "label_val = label_train[:3000]\n",
    "label_train_final = label_train[3000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build the first model that we built, without any regularization or dropout layers included. \n",
    "\n",
    "Train this model for 120 epochs.  All other hyperparameters should stay the same.  Store the fitted model inside of `moredata_model`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.9096 - accuracy: 0.2065 - val_loss: 1.8787 - val_accuracy: 0.2443\n",
      "Epoch 2/120\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.8308 - accuracy: 0.30 - 0s 4ms/step - loss: 1.8263 - accuracy: 0.3098 - val_loss: 1.7769 - val_accuracy: 0.3420\n",
      "Epoch 3/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 1.6853 - accuracy: 0.4144 - val_loss: 1.6001 - val_accuracy: 0.4650\n",
      "Epoch 4/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4814 - accuracy: 0.5198 - val_loss: 1.3862 - val_accuracy: 0.5567\n",
      "Epoch 5/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2737 - accuracy: 0.5988 - val_loss: 1.1940 - val_accuracy: 0.6350\n",
      "Epoch 6/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.0976 - accuracy: 0.6551 - val_loss: 1.0413 - val_accuracy: 0.6707\n",
      "Epoch 7/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.6902 - val_loss: 0.9300 - val_accuracy: 0.6970\n",
      "Epoch 8/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.7143 - val_loss: 0.8518 - val_accuracy: 0.7153\n",
      "Epoch 9/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.7971 - accuracy: 0.7303 - val_loss: 0.7957 - val_accuracy: 0.7287\n",
      "Epoch 10/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.7425 - val_loss: 0.7545 - val_accuracy: 0.7397\n",
      "Epoch 11/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.7534 - val_loss: 0.7237 - val_accuracy: 0.7463\n",
      "Epoch 12/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.7603 - val_loss: 0.6998 - val_accuracy: 0.7540\n",
      "Epoch 13/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.7682 - val_loss: 0.6812 - val_accuracy: 0.7567\n",
      "Epoch 14/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.7723 - val_loss: 0.6644 - val_accuracy: 0.7630\n",
      "Epoch 15/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7793 - val_loss: 0.6511 - val_accuracy: 0.7690\n",
      "Epoch 16/120\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.6022 - accuracy: 0.7840 - val_loss: 0.6401 - val_accuracy: 0.7780\n",
      "Epoch 17/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5895 - accuracy: 0.7870 - val_loss: 0.6323 - val_accuracy: 0.7743\n",
      "Epoch 18/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5778 - accuracy: 0.7921 - val_loss: 0.6223 - val_accuracy: 0.7800\n",
      "Epoch 19/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7954 - val_loss: 0.6159 - val_accuracy: 0.7860\n",
      "Epoch 20/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.8000 - val_loss: 0.6089 - val_accuracy: 0.7887\n",
      "Epoch 21/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.8025 - val_loss: 0.6034 - val_accuracy: 0.7887\n",
      "Epoch 22/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.8055 - val_loss: 0.5970 - val_accuracy: 0.7900\n",
      "Epoch 23/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8082 - val_loss: 0.5938 - val_accuracy: 0.7930\n",
      "Epoch 24/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5261 - accuracy: 0.8104 - val_loss: 0.5890 - val_accuracy: 0.7930\n",
      "Epoch 25/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8143 - val_loss: 0.5856 - val_accuracy: 0.7963\n",
      "Epoch 26/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5128 - accuracy: 0.8165 - val_loss: 0.5812 - val_accuracy: 0.7963\n",
      "Epoch 27/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.8182 - val_loss: 0.5776 - val_accuracy: 0.7953\n",
      "Epoch 28/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.8208 - val_loss: 0.5748 - val_accuracy: 0.7990\n",
      "Epoch 29/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.8223 - val_loss: 0.5728 - val_accuracy: 0.7980\n",
      "Epoch 30/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.4900 - accuracy: 0.8251 - val_loss: 0.5689 - val_accuracy: 0.7990\n",
      "Epoch 31/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8260 - val_loss: 0.5665 - val_accuracy: 0.7950\n",
      "Epoch 32/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.4800 - accuracy: 0.8285 - val_loss: 0.5663 - val_accuracy: 0.7970\n",
      "Epoch 33/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8306 - val_loss: 0.5632 - val_accuracy: 0.7997\n",
      "Epoch 34/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8328 - val_loss: 0.5606 - val_accuracy: 0.8040\n",
      "Epoch 35/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8345 - val_loss: 0.5615 - val_accuracy: 0.8010\n",
      "Epoch 36/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.8364 - val_loss: 0.5587 - val_accuracy: 0.8013\n",
      "Epoch 37/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8363 - val_loss: 0.5570 - val_accuracy: 0.8007\n",
      "Epoch 38/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8394 - val_loss: 0.5545 - val_accuracy: 0.8050\n",
      "Epoch 39/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8408 - val_loss: 0.5540 - val_accuracy: 0.8083\n",
      "Epoch 40/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.8420 - val_loss: 0.5526 - val_accuracy: 0.8087\n",
      "Epoch 41/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8430 - val_loss: 0.5523 - val_accuracy: 0.8100\n",
      "Epoch 42/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8437 - val_loss: 0.5538 - val_accuracy: 0.8083\n",
      "Epoch 43/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8457 - val_loss: 0.5508 - val_accuracy: 0.8110\n",
      "Epoch 44/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8465 - val_loss: 0.5500 - val_accuracy: 0.8090\n",
      "Epoch 45/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8479 - val_loss: 0.5496 - val_accuracy: 0.8077\n",
      "Epoch 46/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8483 - val_loss: 0.5476 - val_accuracy: 0.8097\n",
      "Epoch 47/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8505 - val_loss: 0.5481 - val_accuracy: 0.8107\n",
      "Epoch 48/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8497 - val_loss: 0.5465 - val_accuracy: 0.8100\n",
      "Epoch 49/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8527 - val_loss: 0.5469 - val_accuracy: 0.8077\n",
      "Epoch 50/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8530 - val_loss: 0.5489 - val_accuracy: 0.8130\n",
      "Epoch 51/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8548 - val_loss: 0.5464 - val_accuracy: 0.8103\n",
      "Epoch 52/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8557 - val_loss: 0.5447 - val_accuracy: 0.8097\n",
      "Epoch 53/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8567 - val_loss: 0.5445 - val_accuracy: 0.8083\n",
      "Epoch 54/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8579 - val_loss: 0.5462 - val_accuracy: 0.8093\n",
      "Epoch 55/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8577 - val_loss: 0.5452 - val_accuracy: 0.8093\n",
      "Epoch 56/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8593 - val_loss: 0.5442 - val_accuracy: 0.8103\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8608 - val_loss: 0.5487 - val_accuracy: 0.8080\n",
      "Epoch 58/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8608 - val_loss: 0.5476 - val_accuracy: 0.8073\n",
      "Epoch 59/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8627 - val_loss: 0.5451 - val_accuracy: 0.8087\n",
      "Epoch 60/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8628 - val_loss: 0.5452 - val_accuracy: 0.8080\n",
      "Epoch 61/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8635 - val_loss: 0.5446 - val_accuracy: 0.8077\n",
      "Epoch 62/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8645 - val_loss: 0.5451 - val_accuracy: 0.8110\n",
      "Epoch 63/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8642 - val_loss: 0.5464 - val_accuracy: 0.8110\n",
      "Epoch 64/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8659 - val_loss: 0.5446 - val_accuracy: 0.8083\n",
      "Epoch 65/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8659 - val_loss: 0.5461 - val_accuracy: 0.8120\n",
      "Epoch 66/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8677 - val_loss: 0.5485 - val_accuracy: 0.8087\n",
      "Epoch 67/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.8670 - val_loss: 0.5462 - val_accuracy: 0.8117\n",
      "Epoch 68/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8678 - val_loss: 0.5457 - val_accuracy: 0.8107\n",
      "Epoch 69/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8699 - val_loss: 0.5463 - val_accuracy: 0.8097\n",
      "Epoch 70/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8697 - val_loss: 0.5465 - val_accuracy: 0.8097\n",
      "Epoch 71/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8704 - val_loss: 0.5483 - val_accuracy: 0.8087\n",
      "Epoch 72/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8718 - val_loss: 0.5483 - val_accuracy: 0.8117\n",
      "Epoch 73/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8718 - val_loss: 0.5492 - val_accuracy: 0.8123\n",
      "Epoch 74/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8732 - val_loss: 0.5480 - val_accuracy: 0.8103\n",
      "Epoch 75/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8731 - val_loss: 0.5484 - val_accuracy: 0.8113\n",
      "Epoch 76/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8738 - val_loss: 0.5507 - val_accuracy: 0.8107\n",
      "Epoch 77/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.8744 - val_loss: 0.5513 - val_accuracy: 0.8110\n",
      "Epoch 78/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8751 - val_loss: 0.5549 - val_accuracy: 0.8103\n",
      "Epoch 79/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8758 - val_loss: 0.5511 - val_accuracy: 0.8120\n",
      "Epoch 80/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8760 - val_loss: 0.5508 - val_accuracy: 0.8107\n",
      "Epoch 81/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8766 - val_loss: 0.5518 - val_accuracy: 0.8117\n",
      "Epoch 82/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8775 - val_loss: 0.5523 - val_accuracy: 0.8107\n",
      "Epoch 83/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8782 - val_loss: 0.5550 - val_accuracy: 0.8133\n",
      "Epoch 84/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8795 - val_loss: 0.5539 - val_accuracy: 0.8093\n",
      "Epoch 85/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8791 - val_loss: 0.5543 - val_accuracy: 0.8120\n",
      "Epoch 86/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8799 - val_loss: 0.5566 - val_accuracy: 0.8100\n",
      "Epoch 87/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8804 - val_loss: 0.5575 - val_accuracy: 0.8130\n",
      "Epoch 88/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8811 - val_loss: 0.5563 - val_accuracy: 0.8113\n",
      "Epoch 89/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8820 - val_loss: 0.5599 - val_accuracy: 0.8140\n",
      "Epoch 90/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8816 - val_loss: 0.5580 - val_accuracy: 0.8093\n",
      "Epoch 91/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8832 - val_loss: 0.5627 - val_accuracy: 0.8113\n",
      "Epoch 92/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8834 - val_loss: 0.5628 - val_accuracy: 0.8093\n",
      "Epoch 93/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8830 - val_loss: 0.5615 - val_accuracy: 0.8103\n",
      "Epoch 94/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8848 - val_loss: 0.5624 - val_accuracy: 0.8073\n",
      "Epoch 95/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8843 - val_loss: 0.5631 - val_accuracy: 0.8073\n",
      "Epoch 96/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8849 - val_loss: 0.5627 - val_accuracy: 0.8090\n",
      "Epoch 97/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8856 - val_loss: 0.5646 - val_accuracy: 0.8097\n",
      "Epoch 98/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8860 - val_loss: 0.5645 - val_accuracy: 0.8077\n",
      "Epoch 99/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8866 - val_loss: 0.5658 - val_accuracy: 0.8073\n",
      "Epoch 100/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8868 - val_loss: 0.5687 - val_accuracy: 0.8060\n",
      "Epoch 101/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8866 - val_loss: 0.5687 - val_accuracy: 0.8043\n",
      "Epoch 102/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8879 - val_loss: 0.5673 - val_accuracy: 0.8093\n",
      "Epoch 103/120\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.8894 - val_loss: 0.5697 - val_accuracy: 0.8040\n",
      "Epoch 104/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3196 - accuracy: 0.8885 - val_loss: 0.5735 - val_accuracy: 0.8100\n",
      "Epoch 105/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3182 - accuracy: 0.8895 - val_loss: 0.5712 - val_accuracy: 0.8067\n",
      "Epoch 106/120\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3171 - accuracy: 0.8901 - val_loss: 0.5713 - val_accuracy: 0.8083\n",
      "Epoch 107/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.8898 - val_loss: 0.5728 - val_accuracy: 0.8080\n",
      "Epoch 108/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8915 - val_loss: 0.5759 - val_accuracy: 0.8057\n",
      "Epoch 109/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8914 - val_loss: 0.5747 - val_accuracy: 0.8067\n",
      "Epoch 110/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8920 - val_loss: 0.5753 - val_accuracy: 0.8040\n",
      "Epoch 111/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8932 - val_loss: 0.5758 - val_accuracy: 0.8047\n",
      "Epoch 112/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8934 - val_loss: 0.5782 - val_accuracy: 0.8083\n",
      "Epoch 113/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8935 - val_loss: 0.5831 - val_accuracy: 0.8027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8938 - val_loss: 0.5805 - val_accuracy: 0.8040\n",
      "Epoch 115/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.8942 - val_loss: 0.5815 - val_accuracy: 0.8053\n",
      "Epoch 116/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8949 - val_loss: 0.5828 - val_accuracy: 0.8063\n",
      "Epoch 117/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8943 - val_loss: 0.5828 - val_accuracy: 0.8063\n",
      "Epoch 118/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8957 - val_loss: 0.5844 - val_accuracy: 0.8067\n",
      "Epoch 119/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8965 - val_loss: 0.5870 - val_accuracy: 0.8037\n",
      "Epoch 120/120\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8965 - val_loss: 0.5888 - val_accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_shape = (2000, ))) \n",
    "model.add(Dense(25, activation = 'relu'))\n",
    "model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_val = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, let's check the results returned from `model.evaluate()` to see how this model stacks up with the other techniques we've used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 1s 516us/step - loss: 0.2967 - accuracy: 0.8989\n",
      "125/125 [==============================] - 0s 752us/step - loss: 0.6203 - accuracy: 0.7918\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)\n",
    "results_test = model.evaluate(test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2966914772987366, 0.898878812789917]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train # Expected Output:  [0.31160746300942971, 0.89160606060606062]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6202676892280579, 0.7917500138282776]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test # Expected Output: [0.56076071488857271, 0.8145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, we were able to get a fairly similar validation accuracy of 89.1%. Our test set accuracy went up from ~75% to a staggering 81.45% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
